{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as pylab\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "pylab.rcParams['figure.figsize'] = 10, 10\n",
    "plt.rc(\"font\", size=8)\n",
    "\n",
    "plt.rc('xtick', color='k', labelsize='medium', direction='in')\n",
    "plt.rc('xtick.major', size=8, pad=12)\n",
    "plt.rc('xtick.minor', size=8, pad=12)\n",
    "\n",
    "plt.rc('ytick', color='k', labelsize='medium', direction='in')\n",
    "plt.rc('ytick.major', size=8, pad=12)\n",
    "plt.rc('ytick.minor', size=8, pad=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "## Table Of Content: <a id='toc'></a>\n",
    "\n",
    "* [Introduction](#intro)\n",
    "\n",
    "* [Data exploration](#Exploration)\n",
    "\n",
    "\n",
    "* [Linear regression](#Linear-Regression)\n",
    "\n",
    "    * [ML approach to linear regression - diabetes data](#LR-1)\n",
    "    * [Adding regularization to the linear regression](#LR-regul)\n",
    "    \n",
    "* [KNN](#KNN)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* [Random Forest](#rf-r)\n",
    "\n",
    "\n",
    "\n",
    "* [Exercise](#exo)\n",
    "\n",
    "* [Appendices](#APPENDIX)\n",
    "\n",
    "    * [SVM](#SVM)\n",
    "    * [Gradient Boosting](#Gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction : re-framing the target <a id='intro'></a>\n",
    "\n",
    "In that part we will use all the algorithms seen previously but in the case of a regression rather than a classification.\n",
    "\n",
    "**The difference is that now our target vector (i.e. what we want to predict) is not a class (a discrete variable) but rather a number that can take a continuity of values.**\n",
    "\n",
    "The algorithms are going to use very similar methods than the ones used in classification (if there are particularities between using a method as a classifier and using the same method as a regressor I will mention it).\n",
    "\n",
    "**What's mainly going to change is the loss function used to train your model and the scoring used to evaluate this model.**\n",
    "\n",
    "**For classification** we saw two main types of **loss function**:\n",
    "\n",
    "- Cross entropy (negative loglikelihood) : all the classifiers except SVM and KNN (because KNN doesn't learn through a loss function). Note : GINI impurity is a form of entropy.\n",
    "\n",
    "- Hinge loss function : SVM classifier.\n",
    "\n",
    "And plenty of **scoring systems**, but at least two in depth:\n",
    "\n",
    "- Accuracy\n",
    "\n",
    "- Area under the ROC curve.\n",
    "\n",
    "Note that we could have used the value of the minimized loss function as a score. But for classification problems since the loss function can be different from one model to another, the values of the loss function can be hard to compare and you will prefer a scoring method independent of your loss function.\n",
    "\n",
    "### In regression problems the loss functions and the scoring are metrics that you probably have seen before and so are more intuitive.\n",
    "\n",
    "The **two main loss functions that you will minimize while training your model are** :\n",
    "\n",
    "\n",
    "- Mean square error/ quadratic loss/ L2 loss **(MSE)** : $\\frac{\\Sigma^{n}_{i=1}(y_{i}-\\hat{y}_{i})^{2}}{n}$\n",
    "\n",
    "- Mean absolute error/ L1 loss **(MAE)** : $\\frac{\\Sigma^{n}_{i=1}|y_{i}-\\hat{y}_{i}|}{n}$\n",
    "\n",
    "Where \n",
    " * $n$ are the number of training examples\n",
    " * $i$ the $i$-th training example in the data set\n",
    " * $y_{i}$ the ground truth target value for that $i$-th example and \n",
    " * $\\hat{y_{i}}$ the estimated value of the target for the $i$-th example.\n",
    "\n",
    "**Scoring to consider** here can actually be the value of the minimized loss function used (MSE or MAE) or other scoring metrics like :\n",
    "\n",
    "- **R squared** : $1-\\frac{\\Sigma^{n}_{i=1}(y_{i}-\\hat{y}_{i})^{2}}{\\Sigma^{n}_{i=1}(y_{i}-\\bar{y}_{i})^{2}}$\n",
    "\n",
    "Proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model\n",
    "\n",
    "- **Adjusted R squared** : $1-(1-\\frac{\\Sigma^{n}_{i=1}(y_{i}-\\hat{y}_{i})^{2}}{\\Sigma^{n}_{i=1}(y_{i}-\\bar{y}_{i})^{2}}\\frac{n-1}{n-(k+1)})$ , with k the degree of freedom.\n",
    "\n",
    "Adjusted R-squared is similar to R-squared, but it takes into account the number of variables in the model.\n",
    "\n",
    "- **Max error** : $max(|y_{i}-\\hat{y}_{i}|)$\n",
    "\n",
    "- **Variance explained** : $1-\\frac{Var(\\{y_{i}-\\bar{y}_{i}\\}_{i})}{Var(\\{y_{i}\\}_{i})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We will use a DNA methylation dataset from [Naue etal. 2017](https://www.sciencedirect.com/science/article/pii/S1872497317301643?via%3Dihub), as prepared for another [regression tutorial from the GTN](https://training.galaxyproject.org/training-material/topics/statistics/tutorials/regression_machinelearning/tutorial.html).\n",
    "\n",
    "It consists in measurements of the methylation levels of 13 biomarkers to try to predict age.\n",
    "\n",
    "The train and the test data have already been separated in two separate tables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_meth = pd.read_table( \"https://zenodo.org/record/2545213/files/train_rows.csv\" )\n",
    "df_meth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meth_test = pd.read_table(\"https://zenodo.org/record/2545213/files/test_rows_labels.csv\")\n",
    "df_meth_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to ToC](#toc)\n",
    "\n",
    "# A little bit on data exploration for regression <a class=\"anchor\" id=\"Exploration\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's check how the different features and the target interact with each others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meth_corr = df_meth.corr()\n",
    "\n",
    "sns.clustermap(df_meth_corr,\n",
    "               figsize=(10,10),\n",
    "               z_score=None,\n",
    "               row_cluster=True,\n",
    "               col_cluster=True,\n",
    "               method='ward',\n",
    "               cmap='coolwarm',vmax=1,vmin=-1, \n",
    "               annot=True, annot_kws={\"size\": 13},cbar_kws={\"label\": 'Pearson\\ncorrelation'})\n",
    "## sns allows you to do a hierarchical clustering that simply\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that ELOVL2_6 has a very high correlation with age. Perhaps a model with just this marker would be enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(df_meth , x = 'ELOVL2_6' , y = 'Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the ToC](#toc)\n",
    "\n",
    "# Linear regression <a class=\"anchor\" id=\"Linear-Regression\"></a>\n",
    "\n",
    "We will start with a reduced dataset for visualization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "X_ELOVL2_6 = X_meth.loc[:,[\"ELOVL2_6\"]]\n",
    "\n",
    "## to plot nice curves, it is interesting to get an ordered version of X\n",
    "## points sorted by their values of ELOVL2_6\n",
    "ELOVL2_6_sorted = X_ELOVL2_6.sort_values(by = \"ELOVL2_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, as we will build a simple linear model with a single feature, we actually have no hyper-parameter at this point.\n",
    "\n",
    "So we can just build the model with `LinearRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "## building and fitting model\n",
    "lr=LinearRegression()\n",
    "lr.fit(X_ELOVL2_6,y_meth)\n",
    "\n",
    "## prediction and scoring\n",
    "y_predict=lr.predict(X_ELOVL2_6)\n",
    "\n",
    "R2=r2_score(y_meth,y_predict)\n",
    "RMSE=root_mean_squared_error(y_meth,y_predict)\n",
    "\n",
    "\n",
    "## plotting\n",
    "\n",
    "plt.plot(X_ELOVL2_6.ELOVL2_6,y_meth,'ko',label='Data')\n",
    "\n",
    "plt.plot(ELOVL2_6_sorted.ELOVL2_6, \n",
    "         lr.predict( ELOVL2_6_sorted ) ,\n",
    "         'r-.',label='Predicted', linewidth = 3)\n",
    "\n",
    "plt.legend(loc='best',fontsize=10)\n",
    "\n",
    "plt.title('R2={0:.2f}, RMSE={1:.2f}'.format(R2,RMSE))\n",
    "\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to compute a cross-validated score for this simple model we can use `cross_val_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_r2 = cross_val_score( LinearRegression() ,  \n",
    "                               X_ELOVL2_6 , y_meth , scoring='r2', cv = 5 )\n",
    "\n",
    "## NB: the built-in scorers want to have a score which should be maximized,\n",
    "##     so instead of RMSE, it compute negative RMSE\n",
    "cross_val_RMSE = cross_val_score( LinearRegression() , \n",
    "                                 X_ELOVL2_6 , y_meth , scoring='neg_root_mean_squared_error', cv = 5 )\n",
    "\n",
    "print(f\"cross-validated R2: {cross_val_r2.mean():.2f}\")\n",
    "print(f\"cross-validated RMSE: {-1 * cross_val_RMSE.mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems OK-ish, but if you have some experience with linear models you may see something peculiar.\n",
    "\n",
    "It becomes more apparent when you look at residuals (ie. error from the model):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot( x = X_ELOVL2_6.ELOVL2_6 , y = residuals , lowess=True)\n",
    "plt.axhline(y=0, color='black')\n",
    "plt.ylabel(\"residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern of residuals may be indicative of a higher order relationship between the marker and age.\n",
    "\n",
    "But if that's the case, what is an appropriate degree for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "## plotting\n",
    "ax.plot(X_ELOVL2_6.ELOVL2_6,y_meth,'ko',label='Data')\n",
    "\n",
    "for i,degree in enumerate([2,3,40]):\n",
    "\n",
    "\n",
    "\n",
    "    X = PolynomialFeatures(degree = degree).fit_transform(StandardScaler().fit_transform(X_ELOVL2_6))\n",
    "    Xo = PolynomialFeatures(degree = degree).fit_transform(StandardScaler().fit_transform(ELOVL2_6_sorted) )\n",
    "    y = y_meth \n",
    "\n",
    "    lr = LinearRegression()\n",
    "    lr.fit( X,y )\n",
    "\n",
    "    ## prediction and scoring\n",
    "    y_predict=lr.predict(X)\n",
    "\n",
    "    ax.plot(ELOVL2_6_sorted.ELOVL2_6, \n",
    "            lr.predict( Xo ) ,\n",
    "            '-.',label=f'degree: {degree}', linewidth = 3)\n",
    "\n",
    "    \n",
    "    R2=r2_score(y,y_predict)\n",
    "    RMSE=root_mean_squared_error(y,y_predict)\n",
    "    \n",
    "    print(f'degree: {degree} - R2={R2:.2f}, RMSE={RMSE:.2f}')\n",
    "    \n",
    "ax.legend(loc='best')\n",
    "ax.set_xlabel('ELOVL2_6')\n",
    "ax.set_ylabel('age')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* which degree relationship is appropriate then ?\n",
    " * what of the other biomarkers ?\n",
    "\n",
    "You guessed it, we come back again to hyper-parameters we have to evaluate in order to find the most appropriate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "pipeline_lr=Pipeline([('scalar',StandardScaler()),\n",
    "                      ('poly',PolynomialFeatures(include_bias=False)),\n",
    "                      ('model',LinearRegression())])\n",
    "\n",
    "\n",
    "# define the hyperparameters you want to test with their range to be tested\n",
    "grid_values = {'poly__degree': [1,2,3,4,5]}\n",
    "\n",
    "# Feed them to GridSearchCV with the right score (R squared)\n",
    "grid_lr = GridSearchCV(pipeline_lr, \n",
    "                       param_grid = grid_values, \n",
    "                       scoring=['r2','neg_root_mean_squared_error'],\n",
    "                       refit = 'r2',\n",
    "                       cv = 5,\n",
    "                       n_jobs = -1)\n",
    "\n",
    "grid_lr.fit(X_ELOVL2_6,y_meth)\n",
    "\n",
    "\n",
    "print(f'Grid best score (r2): {grid_lr.best_score_:.3f}' )\n",
    "print( 'Grid best parameter (max. r2): ')\n",
    "for k,v in grid_lr.best_params_.items():\n",
    "    print( f'\\t{k} -> {v}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame( grid_lr.cv_results_ )\n",
    "df_res[ [\"param_poly__degree\",\"mean_test_r2\",\"mean_test_neg_root_mean_squared_error\"] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that increasing power to 3 increases (at least a bit) our predictive power here.\n",
    "\n",
    "But what about the other predictors? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the ToC](#toc)\n",
    "\n",
    "## ML approach to linear regression - methylation data <a id='LR-1'></a>\n",
    "\n",
    "As we add other predictors, it can be good to also add penalization terms.\n",
    "\n",
    "To enable this we switch from `LinearRegression` to `SGDRegressor` which uses Stochastic Gradient Descent to find the optimal weigths for the penalized score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "\n",
    "ppl_meth=Pipeline([('scalar',StandardScaler()),\n",
    "                   ('poly',PolynomialFeatures(include_bias=False)),\n",
    "                   ('model',SGDRegressor( penalty = 'elasticnet' ))])\n",
    "\n",
    "\n",
    "# the interaction_only parameter of PolynomialFeature \n",
    "# lets us test a case with interaction terms but no higher order terms.\n",
    "grid_values = {'poly__degree': [1,2,3],\n",
    "               'poly__interaction_only':[False,True], \n",
    "               'model__alpha' : np.logspace( -2,2,20 ),\n",
    "               'model__l1_ratio' : np.linspace(0.0,1.0,11)\n",
    "              }\n",
    "\n",
    "# Feed them to GridSearchCV with the right score (R squared)\n",
    "grid_meth = GridSearchCV(ppl_meth,\n",
    "                         param_grid = grid_values, \n",
    "                         scoring=['r2', 'neg_root_mean_squared_error'],\n",
    "                         refit = 'r2',\n",
    "                         cv = 5,\n",
    "                        n_jobs = -1)\n",
    "\n",
    "grid_meth.fit(X_meth, y_meth)\n",
    "\n",
    "\n",
    "print(f'Grid best score (grid_meth.scoring): {grid_meth.best_score_:.3f}' )\n",
    "print( 'Grid best parameter (max. r2): ')\n",
    "for k,v in grid_meth.best_params_.items():\n",
    "    print( f'\\t{k} -> {v}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = grid_meth.best_estimator_['poly']\n",
    "LR = grid_meth.best_estimator_['model']\n",
    "\n",
    "def pow2name(power, fnames=X_meth.columns ):\n",
    "    n = []\n",
    "    for i,j in enumerate(power):\n",
    "        if j>0:\n",
    "            if j == 1:\n",
    "                n.append( fnames[i] )\n",
    "            else:\n",
    "                n.append( fnames[i]+'^'+str(j) )\n",
    "    return \"_x_\".join(n)\n",
    "    \n",
    "sorted_list=sorted( zip( map( pow2name , poly.powers_) , LR.coef_ ) ,key=itemgetter(1),reverse=True)\n",
    "print('model importances')\n",
    "for f,w in sorted_list:\n",
    "    if w != 0:\n",
    "        print(\"{:>30}\\t{:.2f}\".format(f,w))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = grid_meth.best_estimator_.predict( X_meth)\n",
    "\n",
    "R2=r2_score(y_meth,y_predict)\n",
    "RMSE=root_mean_squared_error(y_meth,y_predict)\n",
    "\n",
    "\n",
    "plt.plot(y_meth,y_predict,'ro',label='Predicted', linewidth = 3)\n",
    "plt.title('R2={0:.2f}, RMSE={1:.2f}'.format(R2,RMSE))\n",
    "plt.axline((20, 20), slope=1, color=\"black\", linestyle='dashed')\n",
    "plt.xlabel('Age - observed')\n",
    "plt.ylabel('Age - predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df_res = pd.DataFrame(grid_meth.cv_results_)\n",
    "print(\"R-squared\")\n",
    "print( df_res.groupby(['param_poly__degree','param_poly__interaction_only'])[ \"mean_test_r2\" ].max() )\n",
    "\n",
    "print(\"neg RMSE\")\n",
    "print( df_res.groupby(['param_poly__degree','param_poly__interaction_only'])[\"mean_test_neg_root_mean_squared_error\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the ToC](#toc)\n",
    "\n",
    "# KNN <a class=\"anchor\" id=\"KNN\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the KNN algorithm for regression.\n",
    "Again you get the K nearest neighbors of the point you want to predict but this time instead of a vote it does a local average of the neighbours value (again weighted or not by their distance to your query point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "help( KNeighborsRegressor )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**micro-exercise:** complete the code below to train a KNN regressor model for the methylation data. Optimize the `n_neighbors` and `weights` hyper-parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "ppl_meth_KNN=Pipeline([('scalar',StandardScaler()),\n",
    "                   ('poly',PolynomialFeatures(include_bias=False)),\n",
    "                   ('model', ... )])\n",
    "\n",
    "\n",
    "\n",
    "grid_values = {'poly__degree': [1,2,3],\n",
    "               'poly__interaction_only':[False,True], \n",
    "               ... ### change things here\n",
    "              }\n",
    "\n",
    "\n",
    "grid_meth_KNN = GridSearchCV(ppl_meth_KNN,\n",
    "                             param_grid = grid_values, \n",
    "                             scoring=['r2', 'neg_root_mean_squared_error'],\n",
    "                             refit = 'r2',\n",
    "                             cv = 5)\n",
    "\n",
    "grid_meth_KNN.fit(X_meth, y_meth)\n",
    "\n",
    "\n",
    "print(f'Grid best score (grid_meth.scoring): {grid_meth_KNN.best_score_:.3f}' )\n",
    "print( 'Grid best parameter (max. r2): ')\n",
    "for k,v in grid_meth_KNN.best_params_.items():\n",
    "    print( f'\\t{k} -> {v}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the corresponding RMSE require some legwork\n",
    "cv_res = pd.DataFrame( grid_meth_KNN.cv_results_ )\n",
    "cv_res.loc[ cv_res.rank_test_r2 == 1 , 'mean_test_neg_root_mean_squared_error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that the model we get from KKN is not bad at all **but** the interpretability is lacking in this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> KNN regressor is not really good at predicting sparse neigborhoods (the predictions for the extreme data points are not accurate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "[Back to the ToC](#toc)\n",
    "\n",
    "<br>\n",
    "\n",
    "## Random Forest <a class=\"anchor\" id=\"rf-r\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the standpoint of tree, the only difference is that now, instead of the entropy or Gini criterion, **the decision which variable to use at any node is made using a regression metric**, such as squared error for example.\n",
    "\n",
    "For example, consider this example of [regression with a single tree](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html), adapted from the sklearn website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Create a random dataset\n",
    "rng = np.random.RandomState(1)\n",
    "X = np.sort(5 * rng.rand(80, 1), axis=0)\n",
    "y = np.sin(X).ravel()\n",
    "y[::5] += 3 * (0.5 - rng.rand(16)) # adding additional noise to some of the points\n",
    "\n",
    "# Fit regression model\n",
    "regr_1 = DecisionTreeRegressor(max_depth=2)\n",
    "regr_2 = DecisionTreeRegressor(max_depth=5)\n",
    "regr_1.fit(X, y)\n",
    "regr_2.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\n",
    "y_1 = regr_1.predict(X_test)\n",
    "y_2 = regr_2.predict(X_test)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize = (14,6))\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
    "plt.plot(X_test, y_1, color=\"cornflowerblue\", label=\"max_depth=2\", linewidth=2)\n",
    "plt.plot(X_test, y_2, color=\"yellowgreen\", label=\"max_depth=5\", linewidth=2)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "plot_tree( regr_1 , \n",
    "          ax=ax , fontsize=10 , filled=True , impurity=False , precision=3)\n",
    "ax.set_title('best single decision tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course with a single tree you do not get very far, unless the tree becomes absolutely huge. \n",
    "\n",
    "But with a random forest you can aggregate the estimate from many trees to get somewhere nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RFReg = RandomForestRegressor(n_estimators=10 )\n",
    "RFReg.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\n",
    "y_1 = regr_1.predict(X_test)\n",
    "y_rf = RFReg.predict(X_test)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize = (14,6))\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
    "plt.plot(X_test, y_1, color=\"cornflowerblue\", label=\"max_depth=2\", linewidth=2)\n",
    "plt.plot(X_test, y_rf, color=\"yellowgreen\", label=\"RF\", linewidth=2)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a bit of leg-work, we can even grab the inidividual trees predictions to build an interval around the random forest prediction: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## collecting prediction from all individual trees in a big list\n",
    "y_pred = []\n",
    "x_pred = []\n",
    "for tree in RFReg.estimators_ :\n",
    "    y_pred += list( tree.predict(X_test) )\n",
    "    x_pred += list(X_test[:,0])\n",
    "\n",
    "\n",
    "plt.figure(figsize = (14,6))\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
    "plt.plot(X_test, y_1, color=\"cornflowerblue\", label=\"max_depth=2\", linewidth=2)\n",
    "plt.plot(X_test, y_rf, color=\"yellowgreen\", label=\"RF\", linewidth=2)\n",
    "sns.lineplot(x=x_pred , y=y_pred , color=\"yellowgreen\" , errorbar = 'sd') \n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try on the methylation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "## when it comes to criterion, we can now choose:\n",
    "# * “squared_error” (default) for the mean squared error, minimizes the L2 loss\n",
    "#                                           using the mean of each terminal node,\n",
    "# * “friedman_mse”, which uses mean squared error with Friedman’s improvement score for potential splits\n",
    "# * “absolute_error” for the mean absolute error, which minimizes the L1 loss\n",
    "#                                           using the median of each terminal node,\n",
    "# * “poisson” which uses reduction in Poisson deviance to find splits.\n",
    "#\n",
    "# let's try squared error and absolute error\n",
    "\n",
    "grid_values = {'criterion': ['squared_error' , 'absolute_error'],\n",
    "               'n_estimators':[1000], \n",
    "               'max_depth':[6,8,10],\n",
    "               'min_samples_split':np.arange(2,23,5)}\n",
    "\n",
    "grid_RF = GridSearchCV(RandomForestRegressor(),\n",
    "                                param_grid = grid_values, \n",
    "                                scoring=['r2', 'neg_root_mean_squared_error'],\n",
    "                                refit = 'r2',\n",
    "                                n_jobs=-1,\n",
    "                                cv=5)\n",
    "\n",
    "grid_RF.fit(X_meth, y_meth)\n",
    "\n",
    "\n",
    "print('Grid best score (r2): ', grid_RF.best_score_)\n",
    "print('Grid best parameter (max. r2): ')\n",
    "\n",
    "for k,v in grid_RF.best_params_.items():\n",
    "    print( f'\\t{k} -> {v}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance=grid_RF.best_estimator_.feature_importances_\n",
    "\n",
    "\n",
    "sorted_features=sorted( list( zip( X_meth.columns , feature_importance ) ),key=itemgetter(1),reverse=True)\n",
    "\n",
    "print('Features sorted per importance in discriminative process')\n",
    "for f,w in sorted_features:\n",
    "    print('{:>20}\\t{:.3f}'.format(f,w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree-based techniques are interesting because:\n",
    " * they do not necessitate scaling\n",
    " * they give interpretable models and results\n",
    " * they model arbitrary non-linear problems\n",
    " \n",
    "However as you have seen they tend to take longer to train..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to ToC](#toc)\n",
    "\n",
    "# Exercise:  <a class=\"anchor\" id=\"exo\"></a>\n",
    "\n",
    "We go back to the potato dataset we introduced in notebook 3.\n",
    "\n",
    "> the model can take even longer than before to train. Be mindful of the parameter space you specify. For instance, if you use a polynomial : do you really want a 3rd degree polynomial exploring all combinations of 15000 genes ? How many parameters would that represent?\n",
    " Again, `SelectKBest`, and/or a preliminary PCA are your friend (use scores adapted to regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try linear regression (with different degrees if you wish) and gradient boosting tree. What do you learn about Flesh Color?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_metadata = \"../data/potato_data.phenotypic.csv\"\n",
    "file_data = \"../data/potato_data.transcriptomic.top200norm.csv\"\n",
    "\n",
    "df = pd.read_csv( file_metadata , index_col=0 )\n",
    "dfTT = pd.read_csv( file_data , index_col=0)\n",
    "\n",
    "X = dfTT\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Flesh Colour\"]\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separate train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 1-6 solutions/solution_04_potato.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding the best linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 8-36 solutions/solution_04_potato.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding the best KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 37-63 solutions/solution_04_potato.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding the best random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 64-85 solutions/solution_04_potato.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choosing the best method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 86-90 solutions/solution_04_potato.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 91-105 solutions/solution_04_potato.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra exercise\n",
    "\n",
    "You can attempt the same thing with the AML dataset we used in the unsupervised learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aml=pd.read_excel('../data/gene_drug_sens.xlsx')\n",
    "X_aml=df_aml[df_aml.columns[9:]] \n",
    "y_aml = df_aml.auc #  <-- this is the target metric\n",
    "X_aml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to ToC](#toc)\n",
    "\n",
    "# Appendices <a class=\"anchor\" id=\"APPENDIX\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the ToC](#toc)\n",
    "\n",
    "# SVM <a class=\"anchor\" id=\"SVM\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SVM regression the algo is almost the same as classifier SVM with one big difference. In classification we were looking at the hyperplane that was as far as possible from our support vectors.\n",
    "In regression you look for the **hyperplanes that are as close as possible from your support vector**.\n",
    "\n",
    "> NB: **Support vectors** are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr=SVR()\n",
    "\n",
    "pipeline_svr=Pipeline([('scalar',StandardScaler()),('model',svr)])\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define the hyperparameters you want to test with their range\n",
    "# kernel: kernel type to be used in the algorithm (function that takes low dimensional input space \n",
    "# and transforms it to a higher dimensional space)\n",
    "# degree: degree of the polynomial kernel function\n",
    "# epsilon: parameters that controls which data points contribute to regularization\n",
    "# C: inverse of regularization strength\n",
    "grid_values = [{\"model\": [SVR(kernel='linear')],\n",
    "                 \"model__C\":np.logspace(-2, 2, 10)},\n",
    "                {\"model\": [SVR(kernel='rbf')],\n",
    "                 \"model__gamma\": np.logspace(-2,1,10)},\n",
    "                {\"model\": [SVR(kernel='poly')],\n",
    "                 \"model__C\":np.logspace(-2, 2, 10),\n",
    "                 \"model__degree\":np.arange(2,10,1)}]\n",
    "\n",
    "# Feed them to GridSearchCV with the right score (R squared)\n",
    "grid_svr_acc = GridSearchCV(pipeline_svr, param_grid = grid_values, scoring='r2')\n",
    "\n",
    "grid_svr_acc.fit(X_diabetes_train, y_diabetes_train)\n",
    "\n",
    "y_decision_fn_scores_acc=grid_svr_acc.score(X_diabetes_test,y_diabetes_test)\n",
    "\n",
    "\n",
    "print('Grid best parameter (max. r2): ', grid_svr_acc.best_params_)\n",
    "print('Grid best score (r2): ', grid_svr_acc.best_score_)\n",
    "print('Grid best parameter (max. r2) model on test: ', y_decision_fn_scores_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kernel = grid_svr_acc.best_estimator_.steps[1][1].kernel\n",
    "if best_kernel=='linear':\n",
    "    \n",
    "    svr = grid_svr_acc.best_estimator_.steps[1][1]\n",
    "    \n",
    "    featureW = pd.DataFrame( {'feature' : diabetes['feature_names'],\n",
    "                                'weight': svr.coef_.flatten()} )\n",
    "\n",
    "    # sort them by absolute value\n",
    "    featureWsorted = featureW.sort_values(by=['weight'] , \n",
    "                                      ascending=False , \n",
    "                                      key=lambda col : col.abs())\n",
    "\n",
    "    # get the non-null ones\n",
    "    print('Features sorted per importance:')\n",
    "    print( featureWsorted.loc[ featureWsorted[\"weight\"] !=0 ] )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the ToC](#toc)\n",
    "\n",
    "# Gradient boosting tree <a class=\"anchor\" id=\"Gradient\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosted is made for regression (you saw that already)! It is even simpler than what we saw before since you don't have to do all those transformations and just go for minimizing the MSE loss function. So let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# define the hyperparameters you want to test with their range\n",
    "grid_values = {'learning_rate':np.logspace(-1,0,5),\n",
    "               'n_estimators':np.arange(25,101,25), \n",
    "               'max_depth':[2,3,4],\n",
    "               'min_samples_split':[10,20],\n",
    "               'min_samples_leaf':[2,5]}\n",
    "\n",
    "# Feed them to GridSearchCV with the right score (R squared)\n",
    "grid_tree = GridSearchCV(GradientBoostingRegressor(), param_grid = grid_values, scoring='r2')\n",
    "\n",
    "grid_tree.fit(X_diabetes_train, y_diabetes_train)\n",
    "\n",
    "y_decision_fn_scores=grid_tree.score(X_diabetes_test,y_diabetes_test)\n",
    "\n",
    "\n",
    "print('Grid best parameter (max. r2): ', grid_tree.best_params_)\n",
    "print('Grid best score (r2): ', grid_tree.best_score_)\n",
    "print('Grid best parameter (max. r2) model on test: ', y_decision_fn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = grid_tree.best_estimator_\n",
    "    \n",
    "featureW = pd.DataFrame( {'feature': diabetes['feature_names'],\n",
    "                        'weight':RFC.feature_importances_} )\n",
    "\n",
    "# sort them by absolute value\n",
    "featureWsorted = featureW.sort_values(by=['weight'] , \n",
    "                                      ascending=False , \n",
    "                                      key=lambda col : col.abs())\n",
    "\n",
    "# get the non-null ones\n",
    "print('Features sorted per importance:')\n",
    "print( featureWsorted.loc[ featureWsorted[\"weight\"] !=0 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_introml2024)",
   "language": "python",
   "name": "conda_introml2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
