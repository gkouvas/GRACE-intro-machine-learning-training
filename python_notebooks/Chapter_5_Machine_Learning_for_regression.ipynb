{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as pylab\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "pylab.rcParams['figure.figsize'] = 10, 10\n",
    "plt.rc(\"font\", size=10)\n",
    "\n",
    "plt.rc('xtick', color='k', labelsize='medium', direction='in')\n",
    "plt.rc('xtick.major', size=8, pad=12)\n",
    "plt.rc('xtick.minor', size=8, pad=12)\n",
    "\n",
    "plt.rc('ytick', color='k', labelsize='medium', direction='in')\n",
    "plt.rc('ytick.major', size=8, pad=12)\n",
    "plt.rc('ytick.minor', size=8, pad=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "## Table Of Content: <a id='toc'></a>\n",
    "\n",
    "* [Introduction](#intro)\n",
    "\n",
    "* [Data exploration](#Exploration)\n",
    "\n",
    "\n",
    "* [Linear regression](#Linear-Regression)\n",
    "\n",
    "    * [ML approach to linear regression - diabetes data](#LR-1)\n",
    "    * [Adding regularization to the linear regression](#LR-regul)\n",
    "    \n",
    "* [KNN](#KNN)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* [Random Forest](#rf-r)\n",
    "\n",
    "\n",
    "\n",
    "* [Exercise](#exo)\n",
    "\n",
    "* [Appendices](#APPENDIX)\n",
    "\n",
    "    * [SVM](#SVM)\n",
    "    * [Gradient Boosting](#Gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction : re-framing the target <a id='intro'></a>\n",
    "\n",
    "In that part we will use all the algorithms seen previously but in the case of a regression rather than a classification.\n",
    "\n",
    "**The difference is that now our target vector (i.e. what we want to predict) is not a class (a discrete variable) but rather a number that can take a continuity of values.**\n",
    "\n",
    "The algorithms are going to use very similar methods than the ones used in classification (if there are particularities between using a method as a classifier and using the same method as a regressor I will mention it).\n",
    "\n",
    "**What's mainly going to change is the loss function used to train your model and the scoring used to evaluate this model.**\n",
    "\n",
    "**For classification** we saw two main types of **loss function**:\n",
    "\n",
    "- Cross entropy (negative loglikelihood) : all the classifiers except SVM and KNN (because KNN doesn't learn through a loss function). Note : GINI impurity is a form of entropy.\n",
    "\n",
    "- Hinge loss function : SVM classifier.\n",
    "\n",
    "And plenty of **scoring systems**, but at least two in depth:\n",
    "\n",
    "- Accuracy\n",
    "\n",
    "- Area under the ROC curve.\n",
    "\n",
    "Note that we could have used the value of the minimized loss function as a score. But for classification problems since the loss function can be different from one model to another, the values of the loss function can be hard to compare and you will prefer a scoring method independent of your loss function.\n",
    "\n",
    "### In regression problems the loss functions and the scoring are metrics that you probably have seen before and so are more intuitive.\n",
    "\n",
    "The **two main loss functions that you will minimize while training your model are** :\n",
    "\n",
    "\n",
    "- Mean square error/ quadratic loss/ L2 loss **(MSE)** : $\\frac{\\Sigma^{n}_{i=1}(y_{i}-\\hat{y}_{i})^{2}}{n}$\n",
    "\n",
    "- Mean absolute error/ L1 loss **(MAE)** : $\\frac{\\Sigma^{n}_{i=1}|y_{i}-\\hat{y}_{i}|}{n}$\n",
    "\n",
    "Where \n",
    " * $n$ are the number of training examples\n",
    " * $i$ the $i$-th training example in the data set\n",
    " * $y_{i}$ the ground truth target value for that $i$-th example and \n",
    " * $\\hat{y_{i}}$ the estimated value of the target for the $i$-th example.\n",
    "\n",
    "**Scoring to consider** here can actually be the value of the minimized loss function used (MSE or MAE) or other scoring metrics like :\n",
    "\n",
    "- **R squared** : $1-\\frac{\\Sigma^{n}_{i=1}(y_{i}-\\hat{y}_{i})^{2}}{\\Sigma^{n}_{i=1}(y_{i}-\\bar{y}_{i})^{2}}$\n",
    "\n",
    "Proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model\n",
    "\n",
    "- **Adjusted R squared** : $1-(1-\\frac{\\Sigma^{n}_{i=1}(y_{i}-\\hat{y}_{i})^{2}}{\\Sigma^{n}_{i=1}(y_{i}-\\bar{y}_{i})^{2}}\\frac{n-1}{n-(k+1)})$ , with k the degree of freedom.\n",
    "\n",
    "Adjusted R-squared is similar to R-squared, but it takes into account the number of variables in the model.\n",
    "\n",
    "- **Max error** : $max(|y_{i}-\\hat{y}_{i}|)$\n",
    "\n",
    "- **Variance explained** : $1-\\frac{Var(\\{y_{i}-\\bar{y}_{i}\\}_{i})}{Var(\\{y_{i}\\}_{i})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the diabetes dataset to predict \"*diabetes progression*\" thanks to age, sex, body mass index, blood pressure and 6 blood serum measurements.\n",
    "\n",
    "Ten baseline variables, age, sex, body mass index, average blood pressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the response of interest, a quantitative measure of disease progression one year after baseline.\n",
    "\n",
    "Data Set Characteristics:\n",
    "\n",
    "    Number of Instances: 442\n",
    "    Number of Attributes: First 10 columns are numeric predictive values\n",
    "    Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
    "    Attribute Information\n",
    "            age age in years\n",
    "            sex\n",
    "            bmi body mass index\n",
    "            bp average blood pressure\n",
    "            s1 tc, total serum cholesterol\n",
    "            s2 ldl, low-density lipoproteins\n",
    "            s3 hdl, high-density lipoproteins\n",
    "            s4 tch, total cholesterol / HDL\n",
    "            s5 ltg, possibly log of serum triglycerides level\n",
    "            s6 glu, blood sugar level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression dataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "df_diabetes = pd.concat([pd.DataFrame(diabetes['data'],columns=diabetes['feature_names']),\\\n",
    "                       pd.DataFrame(diabetes['target'],columns=['disease progression'])],axis=1)\n",
    "\n",
    "df_diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative way of loading which separates co-variables and target\n",
    "(X_diabetes, y_diabetes) = load_diabetes(return_X_y = True)\n",
    "\n",
    "print(X_diabetes[0:1,:],y_diabetes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to ToC](#toc)\n",
    "\n",
    "# A little bit on data exploration for regression <a class=\"anchor\" id=\"Exploration\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's check how the different features and the target interact with each others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "plt.subplots(figsize=(20,20))\n",
    "k=0\n",
    "for v in diabetes.feature_names:\n",
    "    for u in diabetes.feature_names:\n",
    "        if v!=u:\n",
    "            plt.subplot(len(list(df_diabetes.columns)[:-1]),len(list(df_diabetes.columns)[:-1]),k+1)\n",
    "            plt.scatter(df_diabetes[v], df_diabetes[u], c=df_diabetes['disease progression'], s=10,cmap='plasma')\n",
    "            plt.xlabel(v,fontsize=10)\n",
    "            plt.ylabel(u,fontsize=10)\n",
    "            plt.colorbar()\n",
    "            k+=1\n",
    "        else:\n",
    "            plt.subplot(len(list(df_diabetes.columns)[:-1]),len(list(df_diabetes.columns)[:-1]),k+1)\n",
    "            plt.hist(df_diabetes[v],10)\n",
    "            k+=1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another representation would be to look at the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes_corr = df_diabetes.corr()\n",
    "\n",
    "sns.clustermap(df_diabetes_corr,\n",
    "               figsize=(10,10),\n",
    "               z_score=None,\n",
    "               row_cluster=True,\n",
    "               col_cluster=True,\n",
    "               method='ward',\n",
    "               cmap='coolwarm',vmax=1,vmin=-1, \n",
    "               annot=True, annot_kws={\"size\": 13},cbar_kws={\"label\": 'Pearson\\ncorrelation'})\n",
    "## sns allows you to do a hierarchical clustering that simply\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordered correlation between features and target\n",
    "corre_arr=np.array(df_diabetes_corr)[:,-1]\n",
    "for fname,corr in sorted( zip( df_diabetes.columns[:-1] ,corre_arr )  ,key=itemgetter(1),reverse=True) :\n",
    "    print(\"{}\\t{:.3f}\".format(fname,corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see here that `bmi` and `s5` are the two features that best correlate to our target disease progression.\n",
    "\n",
    "We can choose other metrics to select the best features (i.e. perform features selection) using the `SelectKBest` function from Scikit-learn.\n",
    "The `SelectKBest` method selects the features according to a score. By changing the `'score_func'` parameter we can apply the method for both classification and regression data. Selecting the best features is an important process when we prepare a large dataset for training. It helps us eliminate less important parts of the data and reduce training time.\n",
    "\n",
    "We have the choice between calculating an F-score (`f_regression`) between a feature and the target.\n",
    "\n",
    "> NB: An F-test is a way of comparing the significance of the improvement of a model, with respect to the addition of new variables. You can use it when you have a basic model $M_0$ and a more complicated model $M_1$, which contains all variables from $M_0$ and some more. The F-test tells you if $M_1$ is significantly better than $M_0$, with respect to a p-value.\n",
    "\n",
    "If we think that there is no linear relationship between a feature and the target, we can estimate another score (`mutual_info_regression`).\n",
    "\n",
    "> NB: **Mutual information** (MI) between two random variables is a non-negative value, which measures the dependency between the variables. \n",
    "It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency. The function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# creating the SelectKBest object: looking for the best features (k=2) using the F score\n",
    "skb = SelectKBest(f_regression, k=2)\n",
    "# calculating the F score for each features\n",
    "skb.fit(df_diabetes.iloc[:,:-1], df_diabetes[\"disease progression\"])\n",
    "\n",
    "featurePV = pd.DataFrame( {'feature': df_diabetes.columns[:-1],'pval':skb.pvalues_} )\n",
    "\n",
    "# sort them by absolute value\n",
    "featurePVsorted = featurePV.sort_values(by=['pval'] , \n",
    "                                      ascending=True )\n",
    "\n",
    "# get the non-null ones\n",
    "print('Features sorted per pvalue:')\n",
    "featurePVsorted.loc[ featurePVsorted[\"pval\"] <0.01 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# creating the SelectKBest object: looking for the best features (k=2) using the MI\n",
    "skb = SelectKBest(mutual_info_regression, k=2)\n",
    "# calculating MI for each feature\n",
    "skb.fit(df_diabetes[list(df_diabetes.columns)[:-1]], df_diabetes[list(df_diabetes.columns)[-1]])\n",
    "\n",
    "\n",
    "# note that with F-score we are interested in small pvalues, whereas here we are interested in high MI score\n",
    "# keep only the k=2 best features according to the score\n",
    "X_new=skb.transform(df_diabetes[list(df_diabetes.columns)[:-1]])\n",
    "\n",
    "featureMI = pd.DataFrame( {'feature': df_diabetes.columns[:-1],'MI':skb.scores_} )\n",
    "\n",
    "# sort them by absolute value\n",
    "featureMIsorted = featureMI.sort_values(by=['MI'] , \n",
    "                                      ascending=False )\n",
    "\n",
    "# get the non-null ones\n",
    "print('Features sorted per pvalue:')\n",
    "featureMIsorted.loc[ featureMIsorted[\"MI\"] >0.0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are some differences between the two scores, probably coming from the variyng prominence of non-linear relationships between those features and our target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the ToC](#toc)\n",
    "\n",
    "# Linear regression <a class=\"anchor\" id=\"Linear-Regression\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toy data set where we have only one feature (X is one dimensional) and we want to predict y. \n",
    "# We use a simple model here: y is just a typical third degree polynomial of X with some gaussian noise \n",
    "# (here the coefficient of noise is set to 0.5 but I encourage you to play with it).\n",
    "\n",
    "X=np.ndarray.reshape(np.arange(-1,1,10**-2),200,1)\n",
    "print(np.shape(X))\n",
    "y=[1-3*v+6*v**3 +0.5*np.random.randn() for v in X[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams['figure.figsize'] =5, 5\n",
    "plt.rc(\"font\", size=23)\n",
    "plt.plot(X[:,0],y,'o')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a basic 1D linear regression that you know : \n",
    "\n",
    "We will fit our data with a model of the form y=aX+b and the fit will be done by minimizing the sum of squares of errors. \n",
    "\n",
    "We can evaluate the model either using a R-squared or even the mean square error directly. At first let's not put any regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lr=LinearRegression()\n",
    "lr.fit(X,y)\n",
    "y_predict=lr.predict(X)\n",
    "R2=r2_score(y,y_predict)\n",
    "MSE=mean_squared_error(y,y_predict)\n",
    "\n",
    "plt.plot(X[:,0],y,'ko',label='Data')\n",
    "plt.plot(X[:,0],y_predict,'r-.',label='Predicted', linewidth = 3)\n",
    "plt.legend(loc='best',fontsize=10)\n",
    "plt.title('R2={0:.2f}, MSE={1:.2f}'.format(R2,MSE))\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so that's not great.... But we could have guessed that this model would be bad since it is clearly a third degree polynomial that links X to y. \n",
    "\n",
    "We can do better by using a 'trick' (actually it is a trick that we used before in SVM, and a trick that you can use in logistic regression too!!!). Let's artificially increase the number of dimension of our features set : we calculate $X^{2}$ and $X^{3}$ and consider them as features. \n",
    "\n",
    "After all a polynomial is just a linear combination of different monomials.\n",
    "\n",
    "$y=wX +b$ is a linear combination of X\n",
    "\n",
    "$y=w_{1}X+w_{2}X^{2}+w_{3}X^{3}$ is still a linear combination of feature X, $X^{2}$ and $X^{3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call `from sklearn.preprocessing import PolynomialFeatures` and it will do all those X transformations for you. \n",
    "You might think it is a little bit unecessary to call a function for that, but wait to see when we will have to do the same in higher dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# here we set a third degree polynomial object\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "# do the actual fit and transformation of data\n",
    "X_poly=poly.fit_transform(X)\n",
    "\n",
    "\n",
    "lr=LinearRegression()\n",
    "lr.fit(X_poly,y)\n",
    "y_predict=lr.predict(X_poly)\n",
    "R2=r2_score(y,y_predict)\n",
    "MSE=mean_squared_error(y,y_predict)\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize=(14,7))\n",
    "\n",
    "ax[0].plot(X[:,0],y,'ko',label='Data')\n",
    "ax[0].plot(X[:,0],y_predict,'r-.', linewidth=3,label='Predicted')\n",
    "ax[0].legend(loc='best',fontsize=10)\n",
    "ax[0].set_title('R2={0:.2f}, MSE={1:.2f}'.format(R2,MSE))\n",
    "ax[0].set_xlabel('X')\n",
    "ax[0].set_ylabel('y')\n",
    "\n",
    "\n",
    "ax[1].plot(y,y_predict,'ko')\n",
    "ax[1].set_xlabel('true y')\n",
    "ax[1].set_ylabel('predicted y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('fit param',lr.coef_,lr.intercept_)\n",
    "print('true param',[0,-3,0,6],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can actually do the same for more initial features: let's see with a 2D problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function is a multivariate (2D) polynomial of degree 3 : that's 10 coefficients....\n",
    "# Here I put the noise to 100 but please play with that number \n",
    "# to see how it affects your data and the model predicitions.\n",
    "\n",
    "X2=np.ndarray.reshape(np.random.uniform(-5,5,400),200,2)\n",
    "\n",
    "\n",
    "u = X2[:,0]\n",
    "v = X2[:,1]\n",
    "noise = 100\n",
    "\n",
    "\n",
    "y2=4*v+u+2*v**2+0.5*v*u-1*u**2+6*v**3-0.5*v**2*u+4*v*u*u+5*u**3 +4 +noise*np.random.randn(X2.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.rc(\"font\", size=15)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X2[:,0], X2[:,1], y2, s=20, c=None, depthshade=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## or rather, if you have plotly\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d( x =  X2[:,0], y=X2[:,1], z=y2 , size=[1]*y2.shape[0])\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=3)\n",
    "\n",
    "X_poly=poly.fit_transform(X2)\n",
    "print('The order of polynomials coefficient according to the feature power.') \n",
    "print('For example, [1 0] is our seconde monomial and stand for X1.')\n",
    "print('[1 1] is our 5th monomial and stand for X1*X2')\n",
    "print(poly.powers_)\n",
    "\n",
    "lr=LinearRegression()\n",
    "lr.fit(X_poly,y2)\n",
    "y_predict=lr.predict(X_poly)\n",
    "R2=r2_score(y2,y_predict)\n",
    "MSE=mean_squared_error(y2,y_predict)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax.scatter(X2[:,0], X2[:,1], y2, s=20, c='k', depthshade=True)\n",
    "ax.scatter(X2[:,0],X2[:,1],y_predict ,color='m')\n",
    "ax.set_title('R2={0:.2f}, MSE={1:.2f}'.format(R2,MSE))\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.plot(y2,y_predict,'ko')\n",
    "ax.set_xlabel('true y')\n",
    "ax.set_ylabel('predicted y')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print('fit param',lr.coef_,lr.intercept_)\n",
    "print('true param',[[0,4,1,2,0.5,-1,6,-0.5,4,5],4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## or rather, if you have plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "## make a grid of point to make a surface repr4esenting the model predictions\n",
    "xi = np.linspace(X2[:,0].min(), X2[:,0].max(), 100)\n",
    "yi = np.linspace(X2[:,0].min(), X2[:,0].max(), 100)\n",
    "\n",
    "Xgrid,Ygrid = np.meshgrid(xi,yi)\n",
    "Zgrid=lr.predict( poly.transform(np.stack( (Xgrid.flatten() , Ygrid.flatten()) , axis = 1 )) ).reshape( 100,100 )\n",
    "\n",
    "## plotting \n",
    "trace1 = go.Scatter3d(  x =  X2[:,0], y=X2[:,1], z=y2,\n",
    "                        mode='markers',name='data')\n",
    "\n",
    "trace2 = go.Surface(x=xi,y=yi,z=Zgrid , name='model')\n",
    "\n",
    "fig = go.Figure(data=[trace1, trace2])\n",
    "fig.show(renderer='iframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the function we are fitting is the following:\n",
    "\n",
    "$y=w_{1}X_{1}+w_{2}X_{2}+w_{3}X_{1}^{2}+w_{4}X_{1}X_{2}+w_{5}X_{2}^{2}+w_{6}X_{1}^{3}+w_{7}X_{1}^{2}X_{2}+w_{8}X_{1}X_{2}^2+w_{9}X_{2}^{3}+b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you see that by artificially increasing the number of dimensions of your data you can bring some non linear feature fit into the game and expand your set of models to explore. The only thing you have to do is to consider monomials as features (polynomial feature will compute them for you). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the ToC](#toc)\n",
    "\n",
    "## ML approach to linear regression - diabetes data <a id='LR-1'></a>\n",
    "\n",
    "Now you can already see that the polynomial transformation of your data brings an hyperparameter to be chosen. So we will have to use a pipeline that transforms our data into polynomials of different degree before feeding it to the linear regression, and that pipeline will then be used to find the good polynomial degree thanks to `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from operator import itemgetter\n",
    "\n",
    "X_diabetes_train, X_diabetes_test, y_diabetes_train, y_diabetes_test = train_test_split(X_diabetes, y_diabetes,\n",
    "                                                                                        random_state=794182)\n",
    "\n",
    "lr=LinearRegression()\n",
    "\n",
    "pipeline_lr=Pipeline([('scalar',StandardScaler()),\n",
    "                      ('poly',PolynomialFeatures(include_bias=False)),\n",
    "                      ('model',lr)])\n",
    "\n",
    "\n",
    "# define the hyperparameters you want to test with their range to be tested\n",
    "grid_values = {'poly__degree': np.arange(1,4,1),\n",
    "               'poly__interaction_only':[False,True]}\n",
    "\n",
    "# Feed them to GridSearchCV with the right score (R squared)\n",
    "grid_lr_acc = GridSearchCV(pipeline_lr, param_grid = grid_values, scoring='r2')\n",
    "\n",
    "grid_lr_acc.fit(X_diabetes_train, y_diabetes_train)\n",
    "\n",
    "y_decision_fn_scores_acc=grid_lr_acc.score(X_diabetes_test,y_diabetes_test)\n",
    "\n",
    "\n",
    "\n",
    "print(f'Grid best score (r2): {grid_lr_acc.best_score_:.3f}' )\n",
    "print( 'Grid best parameter (max. r2): ')\n",
    "for k,v in grid_lr_acc.best_params_.items():\n",
    "    print( f'\\t{k} -> {v}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm = grid_lr_acc.best_estimator_\n",
    "y_predict = lrm.predict(X_diabetes_test)\n",
    "\n",
    "R2=r2_score(y_diabetes_test,y_predict)\n",
    "MSE=mean_squared_error(y_diabetes_test,y_predict)\n",
    "\n",
    "\n",
    "plt.plot(y_diabetes_test,y_predict,'ro',label='Predicted', linewidth = 3)\n",
    "plt.title('R2={0:.2f}, MSE={1:.2f}'.format(R2,MSE))\n",
    "plt.axline((0, 0), slope=1, color=\"black\", linestyle='dashed')\n",
    "plt.xlabel('y_diabetes_test')\n",
    "plt.ylabel('y_predict')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = grid_lr_acc.best_estimator_.steps[1][1]\n",
    "LR = grid_lr_acc.best_estimator_.steps[2][1]\n",
    "\n",
    "def pow2name(power, fnames=diabetes['feature_names'] ):\n",
    "    n = []\n",
    "    for i,j in enumerate(power):\n",
    "        if j>0:\n",
    "            n.append( fnames[i]+'^'+str(j) )\n",
    "    return \"_\".join(n)\n",
    "    \n",
    "sorted_list=sorted( zip( map( pow2name , poly.powers_) , LR.coef_ ) ,key=itemgetter(1),reverse=True)\n",
    "print('model importances')\n",
    "for f,w in sorted_list:\n",
    "    print(\"{}\\t{:.2f}\".format(f,w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the ToC](#toc)\n",
    "\n",
    "## Let's add some regularization <a id=\"LR-regul\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge and Lasso regularizations are also known as **‘shrinkage’** methods, because they reduce or shrink the coefficients in the resulting regression. \n",
    "This reduces the variance in the model: as input variables are changed, the model’s prediction changes less than it would have without the regularization. \n",
    "\n",
    "Why would you want to reduce the variance of a model? To **avoid overfit**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Linear model fitted by minimizing a regularized empirical loss with \n",
    "# SGD (Stochastic gradient Descent)\n",
    "# You can change the loss function and the learning rate. \n",
    "# But we will not mess with that here.\n",
    "# The learning rate adjustment is made in a clever way by default\n",
    "# and we will stick to the MSE loss.\n",
    "lr_reg=SGDRegressor()\n",
    "\n",
    "pipeline_lr_reg=Pipeline([('scaler',StandardScaler()),\n",
    "                          ('poly',PolynomialFeatures(include_bias=False)),\n",
    "                          ('model',lr_reg)])\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define the hyperparameters you want to test with their range \n",
    "# Regularization shrinks the coefficient estimates towards zero\n",
    "# l1: Lasso regularization adds another term to the cost function, representing the sum of \n",
    "# the magnitudes of all the coefficients in the model.\n",
    "# l2: Ridge regression follows the same pattern, but the penalty term is the sum of the coefficients squared.\n",
    "\n",
    "# Here alpha is the weight for the regularization: the higher the value, the stronger the regularization\n",
    "grid_values = {'poly__degree': np.arange(1,4,1),\n",
    "               'poly__interaction_only':[False,True],\n",
    "               'model__penalty':['l1','l2'],\n",
    "               'model__alpha':np.logspace(-2,3,20)}\n",
    "\n",
    "# Feed them to GridSearchCV with the right score (R squared)\n",
    "grid_lr_reg_acc = GridSearchCV(pipeline_lr_reg, \n",
    "                               param_grid = grid_values, scoring='r2')\n",
    "\n",
    "grid_lr_reg_acc.fit(X_diabetes_train, y_diabetes_train)\n",
    "\n",
    "y_decision_fn_scores_acc=grid_lr_reg_acc.score(X_diabetes_test,y_diabetes_test)\n",
    "\n",
    "\n",
    "print(f'Grid best score (r2): {grid_lr_reg_acc.best_score_:.3f}')\n",
    "print('Grid best parameter (max. r2): ')\n",
    "for k,v in grid_lr_reg_acc.best_params_.items():\n",
    "    print( f'\\t{k} -> {v}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = grid_lr_reg_acc.best_estimator_.steps[1][1]\n",
    "LR = grid_lr_reg_acc.best_estimator_.steps[2][1]\n",
    "\n",
    "def pow2name(power, fnames=diabetes['feature_names'] ):\n",
    "    n = []\n",
    "    for i,j in enumerate(power):\n",
    "        if j>0:\n",
    "            if j>1:\n",
    "                n.append( fnames[i]+'^'+str(j) )\n",
    "            else:\n",
    "                n.append( fnames[i])\n",
    "    return \"_x_\".join(n)\n",
    "    \n",
    "\n",
    "O = np.argsort( np.abs( LR.coef_ ) )\n",
    "coef_list= list( zip( map( pow2name , poly.powers_) , LR.coef_ ) )\n",
    "sorted_list = [ coef_list[i] for i in O[::-1] ]\n",
    "print('model importances')\n",
    "for f,w in sorted_list:\n",
    "    if w !=0:\n",
    "        print(\"{:>20}\\t{:>5.2f}\".format(f,w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Here,  with an artificial example we can **illustrate how regularization can rescue linear regression when feature vectors are strongly correlated**. \n",
    "\n",
    "First let's investigate how adding highly correlated features changes the error in linear regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "lr=LinearRegression()\n",
    "\n",
    "X_train = X_diabetes_train\n",
    "y_train = y_diabetes_train \n",
    "X_test = X_diabetes_test\n",
    "ncol = X_train.shape[1]\n",
    "\n",
    "#first, our \"stable\" model, with the original data\n",
    "lrm = lr.fit(X_train, y_diabetes_train)\n",
    "\n",
    "y_pred_stable = lrm.predict(X_test)\n",
    "\n",
    "#second, we create an \"unstable\" dataset, \n",
    "# where we add columns with are highly correlated with existing columns\n",
    "# ie, dependent = existing_column + some normal noise\n",
    "X_train_u = pd.DataFrame(X_diabetes_train)\n",
    "X_test_u = pd.DataFrame(X_diabetes_test)\n",
    "for i in np.arange(100):\n",
    "    j = np.random.randint(ncol)\n",
    "    X_train_u['Dependent_{0}'.format(i)] = X_train_u.iloc[:,j] + np.random.normal(0, X_train_u.iloc[:,j].std()/100000, X_train_u.shape[0])\n",
    "    X_test_u['Dependent_{0}'.format(i)] = X_test_u.iloc[:,j] + np.random.normal(0, X_test_u.iloc[:,j].std()/100000, X_test_u.shape[0])\n",
    "    \n",
    "    ## the following 2 lines are specific to cases where we add a lot of columns to a \n",
    "    ## pandas dataFrame. To keep it simple : calling copy re-indexes the columns \n",
    "    X_train_u = X_train_u.copy()\n",
    "    X_test_u = X_test_u.copy()\n",
    "    \n",
    "X_train_u = X_train_u.to_numpy()\n",
    "X_test_u = X_test_u.to_numpy()\n",
    "y_train = y_diabetes_train \n",
    "print(X_train_u.shape)\n",
    "print(X_test_u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we then fit this \"unstable\" model\n",
    "lrm = lr.fit(X_train_u, y_diabetes_train)\n",
    "\n",
    "y_pred_unstable = lrm.predict(X_test_u)\n",
    "\n",
    "print('error (stable):   {:.1f}'.format(mean_squared_error(y_diabetes_test, y_pred_stable)))\n",
    "print('error (unstable): {:.1f}'.format(mean_squared_error(y_diabetes_test, y_pred_unstable)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the presence of the correlated variables causes an increase in the model's performance (mean standard error here).\n",
    "\n",
    "<br>\n",
    "\n",
    "Now let's see how we can use Ridge regularization to improve linear regression, when feature vectors are strongly correlated.\n",
    "\n",
    "Equivalently you could also use lasso or elastic net regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit the stable model\n",
    "rdg=Ridge()\n",
    "lr=LinearRegression()\n",
    "\n",
    "rdgm = rdg.fit(X_train_u, y_diabetes_train)\n",
    "\n",
    "y_pred_unstable_ridge = rdgm.predict(X_test_u)\n",
    "\n",
    "print('error (unstable-ridge): {:.1f}'.format(mean_squared_error(y_diabetes_test, y_pred_unstable_ridge)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the ridge regression allows us to find back something close we what we had without the correlated variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the ToC](#toc)\n",
    "\n",
    "# KNN <a class=\"anchor\" id=\"KNN\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the KNN algorithm for regression.\n",
    "Again you get the K nearest neighbors of the point you want to predict but this time instead of a vote it does a local average of the neighbours value (again weighted or not by their distance to your query point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn=KNeighborsRegressor(n_neighbors=10)\n",
    "knn.fit(X2,y2)\n",
    "y_predict=knn.predict(X2)\n",
    "R2=r2_score(y2,y_predict)\n",
    "MSE=mean_squared_error(y2,y_predict)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax.scatter(X2[:,0], X2[:,1], y2, s=20, c='k', depthshade=True)\n",
    "ax.scatter(X2[:,0],X2[:,1],y_predict ,color='m')\n",
    "ax.set_title('R2={0:.2f}, MSE={1:.2f}'.format(R2,MSE))\n",
    "ax.set_xlabel('X1')\n",
    "ax.set_ylabel('X2')\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.plot(y2,y_predict,'ko')\n",
    "m = min(min(y2),min(y_predict))\n",
    "M = max(max(y2),max(y_predict))\n",
    "ax.plot([m,M],[m,M],'r--')\n",
    "ax.set_xlabel('true y')\n",
    "ax.set_ylabel('predicted y')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN regressor is not really good at predicting sparse neigborhoods (the predictions for the extreme data points are not accurate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "[Back to the ToC](#toc)\n",
    "\n",
    "<br>\n",
    "\n",
    "## Random Forest <a class=\"anchor\" id=\"rf-r\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the standpoint of tree, the only difference is that now, instead of the entropy or Gini criterion, **the decision which variable to use at any node is made using a regression metric**, such as squared error for example.\n",
    "\n",
    "For example, consider this example of [regression with a single tree](https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html), adapted from the sklearn website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Create a random dataset\n",
    "rng = np.random.RandomState(1)\n",
    "X = np.sort(5 * rng.rand(80, 1), axis=0)\n",
    "y = np.sin(X).ravel()\n",
    "y[::5] += 3 * (0.5 - rng.rand(16)) # adding additional noise to some of the points\n",
    "\n",
    "# Fit regression model\n",
    "regr_1 = DecisionTreeRegressor(max_depth=2)\n",
    "regr_2 = DecisionTreeRegressor(max_depth=5)\n",
    "regr_1.fit(X, y)\n",
    "regr_2.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\n",
    "y_1 = regr_1.predict(X_test)\n",
    "y_2 = regr_2.predict(X_test)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize = (14,6))\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
    "plt.plot(X_test, y_1, color=\"cornflowerblue\", label=\"max_depth=2\", linewidth=2)\n",
    "plt.plot(X_test, y_2, color=\"yellowgreen\", label=\"max_depth=5\", linewidth=2)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "plot_tree( regr_1 , \n",
    "          ax=ax , fontsize=10 , filled=True , impurity=False , precision=3)\n",
    "ax.set_title('best single decision tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course with a single tree you do not get very far, unless the tree becomes absolutely huge. \n",
    "\n",
    "But with a random forest you can aggregate the estimate from many trees to get somewhere nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RFReg = RandomForestRegressor(n_estimators=10 )\n",
    "RFReg.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\n",
    "y_1 = regr_1.predict(X_test)\n",
    "y_rf = RFReg.predict(X_test)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize = (14,6))\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
    "plt.plot(X_test, y_1, color=\"cornflowerblue\", label=\"max_depth=2\", linewidth=2)\n",
    "plt.plot(X_test, y_rf, color=\"yellowgreen\", label=\"RF\", linewidth=2)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a bit of leg-work, we can even grab the inidividual trees predictions to build an interval around the random forest prediction: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## collecting prediction from all individual trees in a big list\n",
    "y_pred = []\n",
    "x_pred = []\n",
    "for tree in RFReg.estimators_ :\n",
    "    y_pred += list( tree.predict(X_test) )\n",
    "    x_pred += list(X_test[:,0])\n",
    "\n",
    "\n",
    "plt.figure(figsize = (14,6))\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
    "plt.plot(X_test, y_1, color=\"cornflowerblue\", label=\"max_depth=2\", linewidth=2)\n",
    "plt.plot(X_test, y_rf, color=\"yellowgreen\", label=\"RF\", linewidth=2)\n",
    "sns.lineplot(x=x_pred , y=y_pred , color=\"yellowgreen\" , errorbar = 'sd') \n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try on the diabetes data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_diabetes_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "## when it comes to criterion, we can now choose:\n",
    "# * “squared_error” (default) for the mean squared error, minimizes the L2 loss\n",
    "#                                           using the mean of each terminal node,\n",
    "# * “friedman_mse”, which uses mean squared error with Friedman’s improvement score for potential splits\n",
    "# * “absolute_error” for the mean absolute error, which minimizes the L1 loss\n",
    "#                                           using the median of each terminal node,\n",
    "# * “poisson” which uses reduction in Poisson deviance to find splits.\n",
    "#\n",
    "# let's try squared error and absolute error\n",
    "\n",
    "grid_values = {'criterion': ['squared_error' , 'absolute_error'],\n",
    "               'n_estimators':[500], \n",
    "               'max_depth':[2,4,8],\n",
    "               'min_samples_split':np.arange(2,len(X_diabetes_train)//5,20),\n",
    "              'min_samples_leaf':np.arange(2,len(X_diabetes_train)//5,20)}\n",
    "\n",
    "grid_RF_diabetes = GridSearchCV(RandomForestRegressor(),\n",
    "                                param_grid = grid_values, \n",
    "                                scoring='r2',n_jobs=-1,cv=5)\n",
    "\n",
    "grid_RF_diabetes.fit(X_diabetes_train, y_diabetes_train)\n",
    "\n",
    "\n",
    "print('Grid best score (r2): ', grid_RF_diabetes.best_score_)\n",
    "print('Grid best parameter (max. r2): ', grid_RF_diabetes.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_decision_fn_scores_RF_diabetes=grid_RF_diabetes.score(X_diabetes_test,y_diabetes_test)\n",
    "print('Grid best parameter (max. r2) model on test: ', y_decision_fn_scores_RF_diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_diabetes=grid_RF_diabetes.best_estimator_.feature_importances_\n",
    "\n",
    "sorted_features=sorted([[df_diabetes.columns[i],abs(feature_importance_diabetes[i])] for i in range(len(feature_importance_diabetes))],key=itemgetter(1),reverse=True)\n",
    "\n",
    "print('Features sorted per importance in discriminative process')\n",
    "for f,w in sorted_features:\n",
    "    print('{:>20}\\t{:.3f}'.format(f,w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree-based techniques are interesting because:\n",
    " * they do not necessitate scaling\n",
    " * they give interpretable models and results\n",
    " * they model arbitrary non-linear problems\n",
    " \n",
    "However as you have seen they tend to take longer to train..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to ToC](#toc)\n",
    "\n",
    "# Exercise:  <a class=\"anchor\" id=\"exo\"></a>\n",
    "\n",
    "Go back to the potato dataset and this time instead of classifying by type of color, predict the color directly.\n",
    "\n",
    "> the model can take even longer than before to train. Be mindful of the parameter space you specify. For instance, if you use a polynomial : do you really want a 3rd degree polynomial exploring all combinations of 15000 genes ? How many parameters would that represent?\n",
    " Again, `SelectKBest`, and/or a preliminary PCA are your friend (use scores adapted to regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try linear regression (with different degrees if you wish) and gradient boosting tree. What do you learn about Flesh Color?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/12859_2016_1043_MOESM1_ESM.xlsx' )\n",
    "df.index = df.Genotype\n",
    "df.head()\n",
    "\n",
    "## color is encoded between 0 and 50. \n",
    "y = df[\"Flesh Colour\"]\n",
    "\n",
    "y.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read the sheet containing the transcriptomic data. Thankfully it has already been normalized so we only have minor adjustments to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('../data/12859_2016_1043_MOESM1_ESM.xlsx')\n",
    "dfT = pd.read_excel(xls, 'Transcriptomics data ')\n",
    "\n",
    "# transpose and keep only samples for which we have a target value\n",
    "dfTT = dfT.T.loc[y.index , :]\n",
    "dfTT.columns = dfT.loc[: , 'FeatureNum'].astype(str) \n",
    "dfTT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separate train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 1-6 solutions/solution_04_potato.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding the best linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 8-43 solutions/solution_04_potato.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding the best KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 44-68 solutions/solution_04_potato.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finding the best random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 71-91 solutions/solution_04_potato.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choosing the best method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 93-100 solutions/solution_04_potato.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 101-112 solutions/solution_04_potato.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking at feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 113- solutions/solution_04_potato.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra exercise\n",
    "\n",
    "You can attempt the same thing with the AML dataset we used in the unsupervised learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aml=pd.read_excel('../data/gene_drug_sens.xlsx')\n",
    "X_aml=df_aml[df_aml.columns[9:]] \n",
    "y_aml = df_aml.auc #  <-- this is the target metric\n",
    "X_aml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to ToC](#toc)\n",
    "\n",
    "# Appendices <a class=\"anchor\" id=\"APPENDIX\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the ToC](#toc)\n",
    "\n",
    "# SVM <a class=\"anchor\" id=\"SVM\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SVM regression the algo is almost the same as classifier SVM with one big difference. In classification we were looking at the hyperplane that was as far as possible from our support vectors.\n",
    "In regression you look for the **hyperplanes that are as close as possible from your support vector**.\n",
    "\n",
    "> NB: **Support vectors** are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr=SVR()\n",
    "\n",
    "pipeline_svr=Pipeline([('scalar',StandardScaler()),('model',svr)])\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# define the hyperparameters you want to test with their range\n",
    "# kernel: kernel type to be used in the algorithm (function that takes low dimensional input space \n",
    "# and transforms it to a higher dimensional space)\n",
    "# degree: degree of the polynomial kernel function\n",
    "# epsilon: parameters that controls which data points contribute to regularization\n",
    "# C: inverse of regularization strength\n",
    "grid_values = [{\"model\": [SVR(kernel='linear')],\n",
    "                 \"model__C\":np.logspace(-2, 2, 10)},\n",
    "                {\"model\": [SVR(kernel='rbf')],\n",
    "                 \"model__gamma\": np.logspace(-2,1,10)},\n",
    "                {\"model\": [SVR(kernel='poly')],\n",
    "                 \"model__C\":np.logspace(-2, 2, 10),\n",
    "                 \"model__degree\":np.arange(2,10,1)}]\n",
    "\n",
    "# Feed them to GridSearchCV with the right score (R squared)\n",
    "grid_svr_acc = GridSearchCV(pipeline_svr, param_grid = grid_values, scoring='r2')\n",
    "\n",
    "grid_svr_acc.fit(X_diabetes_train, y_diabetes_train)\n",
    "\n",
    "y_decision_fn_scores_acc=grid_svr_acc.score(X_diabetes_test,y_diabetes_test)\n",
    "\n",
    "\n",
    "print('Grid best parameter (max. r2): ', grid_svr_acc.best_params_)\n",
    "print('Grid best score (r2): ', grid_svr_acc.best_score_)\n",
    "print('Grid best parameter (max. r2) model on test: ', y_decision_fn_scores_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kernel = grid_svr_acc.best_estimator_.steps[1][1].kernel\n",
    "if best_kernel=='linear':\n",
    "    \n",
    "    svr = grid_svr_acc.best_estimator_.steps[1][1]\n",
    "    \n",
    "    featureW = pd.DataFrame( {'feature' : diabetes['feature_names'],\n",
    "                                'weight': svr.coef_.flatten()} )\n",
    "\n",
    "    # sort them by absolute value\n",
    "    featureWsorted = featureW.sort_values(by=['weight'] , \n",
    "                                      ascending=False , \n",
    "                                      key=lambda col : col.abs())\n",
    "\n",
    "    # get the non-null ones\n",
    "    print('Features sorted per importance:')\n",
    "    print( featureWsorted.loc[ featureWsorted[\"weight\"] !=0 ] )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the ToC](#toc)\n",
    "\n",
    "# Gradient boosting tree <a class=\"anchor\" id=\"Gradient\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosted is made for regression (you saw that already)! It is even simpler than what we saw before since you don't have to do all those transformations and just go for minimizing the MSE loss function. So let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# define the hyperparameters you want to test with their range\n",
    "grid_values = {'learning_rate':np.logspace(-1,0,5),\n",
    "               'n_estimators':np.arange(25,101,25), \n",
    "               'max_depth':[2,3,4],\n",
    "               'min_samples_split':[10,20],\n",
    "               'min_samples_leaf':[2,5]}\n",
    "\n",
    "# Feed them to GridSearchCV with the right score (R squared)\n",
    "grid_tree = GridSearchCV(GradientBoostingRegressor(), param_grid = grid_values, scoring='r2')\n",
    "\n",
    "grid_tree.fit(X_diabetes_train, y_diabetes_train)\n",
    "\n",
    "y_decision_fn_scores=grid_tree.score(X_diabetes_test,y_diabetes_test)\n",
    "\n",
    "\n",
    "print('Grid best parameter (max. r2): ', grid_tree.best_params_)\n",
    "print('Grid best score (r2): ', grid_tree.best_score_)\n",
    "print('Grid best parameter (max. r2) model on test: ', y_decision_fn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = grid_tree.best_estimator_\n",
    "    \n",
    "featureW = pd.DataFrame( {'feature': diabetes['feature_names'],\n",
    "                        'weight':RFC.feature_importances_} )\n",
    "\n",
    "# sort them by absolute value\n",
    "featureWsorted = featureW.sort_values(by=['weight'] , \n",
    "                                      ascending=False , \n",
    "                                      key=lambda col : col.abs())\n",
    "\n",
    "# get the non-null ones\n",
    "print('Features sorted per importance:')\n",
    "print( featureWsorted.loc[ featureWsorted[\"weight\"] !=0 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_introml2024)",
   "language": "python",
   "name": "conda_introml2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
