{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as pylab\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from operator import itemgetter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "pylab.rcParams['figure.figsize'] = 5, 5\n",
    "plt.rc(\"font\", size=15)\n",
    "\n",
    "\n",
    "plt.rc('xtick', color='k', labelsize='medium', direction='in')\n",
    "plt.rc('xtick.major', size=8, pad=12)\n",
    "plt.rc('xtick.minor', size=8, pad=12)\n",
    "\n",
    "plt.rc('ytick', color='k', labelsize='medium', direction='in')\n",
    "plt.rc('ytick.major', size=8, pad=12)\n",
    "plt.rc('ytick.minor', size=8, pad=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to learn what a **decision tree** is, how it does classification and what the **hyperparameters** used to define it actually do and stand for.\n",
    "\n",
    "Then we are going to superficially describe how decision trees are basic bricks of more powerful algorithms called **ensemble algorithms**. You will see that these algorithm can be quite diverse. Since they are quite useful and commonly used I will spend some time showing how different they actually are from one another and what that means. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree based classification\n",
    "\n",
    "## Table Of Content:<a id='toc'></a>\n",
    "\n",
    "* [Decision Tree](#Decision-Tree)\n",
    "    * [Toy data : exploring hyperparameters](#DT1)\n",
    "    * [Decision tree on the Cancer data set](#DTcancer)\n",
    "    * [Exercise : Decision tree](#DTexo)\n",
    "* [Random Forest](#Random-Forest)\n",
    "    * [Random forest on the Cancer data set](#RFcancer)\n",
    "* [Exercise](#exo)\n",
    "\n",
    "\n",
    "* [Appendices](#APPENDIX)\n",
    "    * [Ada Boost](#Ada-Boost)\n",
    "    * [Boosted Gradient](#Boosted-Gradient)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the breast cancer dataset is integrated in the sklearn library\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "## we reduce the features because otherwise this problem is a bit too easy ;-)\n",
    "m = list( map( lambda x : x.startswith(\"mean \") , data[\"feature_names\"] ) )\n",
    "\n",
    "\n",
    "X_cancer=data['data'][:,m]\n",
    "\n",
    "# for some reason this dataset has encoded 0 for malignant,\n",
    "# which is extremely counter intuitive\n",
    "# So I choose to switch it to the more intuitive order now\n",
    "y_cancer= 1-data['target']\n",
    "\n",
    "#making it into a dataframe\n",
    "df_cancer=pd.DataFrame(X_cancer,\n",
    "    columns=data[\"feature_names\"][m])\n",
    "\n",
    "df_cancer[\"malignant\"]=y_cancer\n",
    "\n",
    "# 0 : benign\n",
    "# 1 : malignant\n",
    "\n",
    "\n",
    "df_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_cancer_train, X_cancer_test, y_cancer_train, y_cancer_test = train_test_split(X_cancer, y_cancer,\n",
    "                                                   random_state=7, stratify=y_cancer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Backto the ToC](#toc)\n",
    "\n",
    "# Decision tree <a class=\"anchor\" id=\"Decision-Tree\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple **decision tree** reduces your problem into a **hierarchichal sequence of questions** on your features that can be answered by yes or no and which subdivides the data into 2 subgroups on which a new question is asked, and so on and so on.\n",
    "\n",
    "![tree_ex](../images/tree_ex.png)\n",
    "\n",
    "Ok, but a huge number of trees can actually be built just by considering the different orders of questions asked. How does the algorithm deals with this?\n",
    "\n",
    "Quite simply actually: it **tests all the features and chooses the most discriminative** (with respect to your target variable) : the feature where a yes or no question divides the data into 2 subsets which minimizes an **impurity measure**.\n",
    "\n",
    "Imagine you have a dataset with feature color (red or blue) and feature shape (square or circle), and 2 target classes : 1 and 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tree](../images/Tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asking `\"feature color is red\"` gives you the following subgroups:\n",
    " * 10 class 1, and 1 class 2 (`\"feature color is red\" == True`)\n",
    " * 2 class 1, and 11 class 2 (`\"feature color is red\" == False`)\n",
    "\n",
    "Asking `\"feature shape is square\"` gives you:\n",
    " * 5 class 1, and 7 class 2 (`True`) \n",
    " * 7 class 1 and 5 class 2 (`False`)\n",
    " \n",
    " So, you will prefer asking `\"feature color is red?\"` over `\"feature shape is square?\"`: `\"feature color is red?\"` is more discriminative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical variables, the questions test for a specific category.\n",
    "For **numerical variables, the questions use a threshold** to as a yes/no question.  \n",
    "\n",
    "The **threshold is, again, chosen to minimize impurity**. And in turn the best threshold for a variable is used to estimate the discriminativeness of that variable.\n",
    "\n",
    "Of course, you will have to compute this threshold at each step of your tree since at each step you are considering different subdatasets.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **impurity is related to how much your feature splitting is still having mixed classes**. So the impurity ends up giving a score: either it is a simple [Shannon entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory)) or it is a [Gini coefficient](https://en.wikipedia.org/wiki/Gini_coefficient).\n",
    "\n",
    "#### Shannon Entropy\n",
    "\n",
    "$$Entropy = - \\sum_{j} p_j log_2(p_j)$$\n",
    "\n",
    "This measure is linked to information theory, where the information of an event occuring is the $log_2$ of this event's probability of occuring.\n",
    "For purity, **0 is the best possible score, and 1 the worst**.\n",
    "\n",
    "#### Gini coefficient\n",
    "\n",
    "$$Gini = 1- \\sum_{j} p_j^2$$\n",
    "\n",
    "The idea is to measure the **probability that a dummy classifier mislabels your data**.\n",
    "**0 is best, 1 is worst.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Before going further, just a little bit of vocabulary: \n",
    "* **Trees** are made of **nodes** (where the question is asked and where the splitting occurs). \n",
    "* A **branch** is the outcome of a splitting. \n",
    "* A **leaf** is the last node on a branch (no more splitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Backto the ToC](#toc)\n",
    "\n",
    "## Toy data : exploring hyperparameters <a id=\"DT1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let explore some hyperparameters of this method that, you will see in those examples, act like a regularization:\n",
    "- **Max Tree depth**: the maximum number of consecutive questions to ask\n",
    "- **Min Splitting of nodes**: minimum number of points to consider to make a new rule, outside of the leaves\n",
    "- **Min Splitting of leaves**: minimum number of points to consider to make a new rule, at the leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "    \n",
    "# 120 points, 3 blobs/clusters with some spread=3\n",
    "blob_centers = np.array([[-7,2.5],[6,-10],[8,-3]])\n",
    "blob_stds = [[1,3],[3,6],[3,6]]\n",
    "X_3, y_3 = make_blobs(n_samples = 250, \n",
    "                      centers = blob_centers,\n",
    "                      cluster_std = blob_stds, random_state = 42)\n",
    "\n",
    "\n",
    "plt.scatter(X_3[:,0],X_3[:,1],c=y_3,cmap=plt.cm.coolwarm,edgecolors='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "## creating a decision tree with 1 parameter changed (more on that later)\n",
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "tree.fit(X_3, y_3)\n",
    "\n",
    "pd.crosstab( tree.predict( X_3 ) , y_3 , rownames=['truth'] , colnames=['prediction'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "fig,ax = plt.subplots(figsize=(14,6))\n",
    "\n",
    "_ = plot_tree( tree , feature_names=['x','y'] , \n",
    "               fontsize=14 , filled=True , impurity=False , precision=3, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import contour_tree\n",
    "\n",
    "contour_tree(X_3, y_3,\n",
    "              crit = 'entropy',\n",
    "              maxd = None,\n",
    "              min_s = 2,\n",
    "              min_l = 1,\n",
    "              max_f = None)\n",
    "#You can see that there are 5 hyperparameters here. Let's see what they do and what they mean.\n",
    "#I bet you can already guess it is going to be related to regularization....\n",
    "# After X,y you have \n",
    "# * crit = 'entropy' which is one way to calculate impurity (you could also put gini here)\n",
    "# * maxd : the max depth of your tree\n",
    "# * min_s : the number of points that should be concerned by the making of a new rule (splitting of the nodes)\n",
    "# * min_l : #of points that should be considered to make a final leaf classification\n",
    "# * max_f : maximum number of features to consider for making a new rule..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's a really complicated and zealous tree. Look at those boundaries. Clearly if we just let it go like that it is overfitting..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using another impurity measurement\n",
    "contour_tree(X_3, y_3,\n",
    "              crit = 'gini',\n",
    "              maxd = None,\n",
    "              min_s = 2,\n",
    "              min_l = 1,\n",
    "              max_f = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still some overfitting but it is nice to see that the boundaries are different and that impurity calculations, even if very similar, are making a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imposing a limit for the depth of the tree : how many questions you ask (here set to 4)\n",
    "contour_tree(X_3, y_3,\n",
    "              crit = 'entropy',\n",
    "              maxd = 4,\n",
    "              min_s = 2, min_l = 1, max_f = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed only a maximum of 4 splitting events link the root to the leafs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you stopped the tree at some points allowing some misslabelling instead of fitting perfectly the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_tree(X_3, y_3,\n",
    "              crit = 'entropy',\n",
    "              maxd = None,\n",
    "              min_s = 2,\n",
    "              min_l = 5,\n",
    "              max_f = None)\n",
    "# I don't really have a strong feeling about where I should stop the tree depth. \n",
    "# But I have an understanding of this other parameter (here set to 5) \n",
    "# called min_samples_leaf : \n",
    "#     it sets the minimal number of data points that the chain of rules should concern. \n",
    "\n",
    "# eg. Do you really wish to create a whole new set of rules to explain \n",
    "# only one particular data point? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convince yourself that now, rules are made for leafs of at least 4 points contrary to trees that we built before and for which you could have leaves containing only 2 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree is simplified and the boundaries look more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_tree(X_3, y_3,\n",
    "              crit = 'entropy',\n",
    "              maxd = None,\n",
    "              min_s = 20,\n",
    "              min_l = 2,\n",
    "              max_f = None)\n",
    "# Here it is the same as before but this time it applies to nodes instead of leaves\n",
    "# This parameter is called min_samples_split and is set to 20 here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that indeed there is no node splitting concerning less than 20 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 main advantages to this kind of methods:\n",
    "* it works with all types of feature\n",
    "* you don't need to rescale\n",
    "* it already includes non linear fitting\n",
    "\n",
    "**Moreover it is 'easy' to interpret.**\n",
    "\n",
    "But....(yes there is a but, there is no free lunch)\n",
    "\n",
    "Even with all of those hyperparamaters **they are still not great on new data (inaccuracy...).** \n",
    "\n",
    "We will see that in the real data example below and we will see more powerful technics based on decision tree that are more costly but generalize better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This hyperparameter set the number of randomly picked features to consider at each node splitting. By setting it up at `None` we consider all the features. But you could also fix that number as you wish or choose a known good scaling for your data which is either square root of the number of features or log2 of the number of features.\n",
    "\n",
    "> N.B. this only affects node splitting : all the features are considered when the tree is built it is just that you randomly pick from the full set at each node splitting event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the **effect of these parameters on the bias-variance tradeoff with a validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## and we create our own validation dataset\n",
    "X_3_valid, y_3_valid = make_blobs(n_samples = 3000, \n",
    "                                  centers = blob_centers,\n",
    "                                  cluster_std = blob_stds , random_state=654321)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def test_decision_tree_param( X_train, y_train , X_valid , y_valid , param_name , param_range , ax):\n",
    "    \n",
    "    scores_valid = []\n",
    "    scores_train = []\n",
    "\n",
    "    for x in param_range:\n",
    "        tree = DecisionTreeClassifier(**{param_name:x})\n",
    "        tree.fit(X_3,y_3)\n",
    "\n",
    "        y_train_prob = tree.predict_proba(X_train)\n",
    "        y_valid_prob = tree.predict_proba(X_valid)\n",
    "\n",
    "        scores_train.append(roc_auc_score(y_train , y_train_prob, multi_class='ovr'))\n",
    "        scores_valid.append(roc_auc_score(y_valid , y_valid_prob, multi_class='ovr'))\n",
    "\n",
    "\n",
    "    # plotting\n",
    "    ax.plot(param_range, scores_train,'k-',linewidth=5,label='train')\n",
    "    ax.plot(param_range, scores_valid,'r-',linewidth=5,label='valid')\n",
    "    ax.set_xlabel(param_name)\n",
    "    ax.set_ylabel('roc_auc')\n",
    "    ax.set_title(param_name)\n",
    "    ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3 , figsize = (15,5))\n",
    "\n",
    "test_decision_tree_param( X_3, y_3 , X_3_valid , y_3_valid ,\n",
    "                         param_name = \"max_depth\" , param_range=np.arange(1,20) , ax=ax[0])\n",
    "test_decision_tree_param( X_3, y_3 , X_3_valid , y_3_valid ,\n",
    "                         param_name = \"min_samples_split\" , param_range=np.arange(2,200) , ax=ax[1])\n",
    "test_decision_tree_param( X_3, y_3 , X_3_valid , y_3_valid ,\n",
    "                         param_name = \"min_samples_leaf\" , param_range=np.arange(1,200) , ax=ax[2])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>\n",
    "    \n",
    " * **max_depth** : &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#8600; bias, &#8599; variance\n",
    " * **min_samples_split** : &#8599; bias, &#8600; variance\n",
    " * **min_samples_leaf** :&nbsp; &#8599; bias, &#8600; variance\n",
    " \n",
    "</big>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to ToC](#toc)\n",
    "\n",
    "## Decision tree on the Cancer data set <a id='DTcancer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's train our model properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cancer_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# define the hyperparameters you want to test\n",
    "#with the range over which you want it to be tested.\n",
    "grid_values = {'criterion': ['entropy','gini'],\n",
    "               'max_depth':[2,6,10,14],\n",
    "               'min_samples_split':np.arange(2,len(X_cancer_train)//4,5),\n",
    "              'min_samples_leaf':np.arange(2,len(X_cancer_train)//4,5)}\n",
    "\n",
    "grid_tree_roc_auc = GridSearchCV(DecisionTreeClassifier(class_weight='balanced'), \n",
    "                             param_grid = grid_values, \n",
    "                             cv=5,\n",
    "                             scoring='roc_auc',n_jobs=-1)\n",
    "\n",
    "grid_tree_roc_auc.fit(X_cancer_train, y_cancer_train)\n",
    "\n",
    "print(f'Grid best score (max. {grid_tree_roc_auc.scoring}): {grid_tree_roc_auc.best_score_:.3f}')\n",
    "print(f'Grid best parameter (max. {grid_tree_roc_auc.scoring}): ')\n",
    "for k,v in grid_tree_roc_auc.best_params_.items():\n",
    "      print('\\t',k,'->',v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "y_test_score=grid_tree_roc_auc.score(X_cancer_test,y_cancer_test)\n",
    "\n",
    "print('Grid best parameter (max. accuracy) model on test: ', y_test_score)\n",
    "\n",
    "y_cancer_pred_test = grid_tree_roc_auc.predict(X_cancer_test)\n",
    "\n",
    "confusion_m_cancer = confusion_matrix(y_cancer_test, y_cancer_pred_test)\n",
    "\n",
    "plt.figure(figsize=(5.5,4))\n",
    "sns.heatmap(confusion_m_cancer, annot=True)\n",
    "plt.title('test {} : {:.3f}'.format( grid_tree_roc_auc.scoring , y_test_score ))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_estimator(grid_tree_roc_auc,X_cancer_test, y_cancer_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a very complicated tree..... And not performing as well as you would expect from something so complicated...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature importance\n",
    "\n",
    "Feature importance in tree is calculated by checking the amount of impurity reduction link to a feature. We will use it but there are some problems in using that definition of feature importance (the main one being caridnality : if your features have a lot of possible value it becomes easier to find a good impurity splitting compared to a binary feature). A more robust way to do it would be to use permutation importance, which relies on looking at the effect of scrambling the values of a feature and see how much it impacts the model. Try it at some point, even on non tree algorithm [permutation_importance](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = grid_tree_roc_auc.best_estimator_\n",
    "\n",
    "w=tree.feature_importances_#get the weights\n",
    "\n",
    "featureW = pd.DataFrame( {'feature': df_cancer.columns[:-1],\n",
    "                        'weight':w} )\n",
    "\n",
    "# sort them by absolute value\n",
    "featureWsorted = featureW.sort_values(by=['weight'] , \n",
    "                                      ascending=False , \n",
    "                                      key=lambda col : col.abs())\n",
    "\n",
    "# get the non-null ones\n",
    "print('Features sorted per importance:')\n",
    "featureWsorted.loc[ featureWsorted[\"weight\"] !=0 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "fig,ax = plt.subplots(figsize=(25,10))\n",
    "plot_tree( grid_tree_roc_auc.best_estimator_ , \n",
    "          feature_names=df_cancer.columns[:-1] , \n",
    "          ax=ax , fontsize=12 , filled=True , impurity=False , precision=3)\n",
    "ax.set_title('best single decision tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the ToC](#toc)\n",
    "\n",
    "##  Exercise : Decision tree <a id=\"DTexo\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TBD ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to ToC](#toc)\n",
    "\n",
    "# Random Forest <a class=\"anchor\" id=\"Random-Forest\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Random Forest algorithm relies on two main concepts : \n",
    "1. **randomly producing/training many different trees**\n",
    "2. **agglomerating the predictions** of all these trees (mainly averaging)\n",
    "\n",
    "\n",
    "The randomness between trees concerns:\n",
    "* **[bootstrapping](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) of the training dataset**\n",
    "* using only a **random subset of features**\n",
    "\n",
    "\n",
    "**Bootstrapping:** sampling methods in which you randomly draw a subsample from your data, *with replacement*. The created replicate is the same size as the original distribution.\n",
    "\n",
    "I am sure you can see intuitively how that is going to help generalization of our model.\n",
    "\n",
    "So now on top of all the parameters seen before to create each individual trees of the forest, you also have a parameter controlling the number of trees in your forest.\n",
    "\n",
    "\n",
    "> In the following plots we will compare the results of a random forest with a single decision tree with the same hyperparameter values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RF](../images/RF.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import contour_RF\n",
    "contour_RF(X_3, y_3,\n",
    "            n_tree = 10,\n",
    "            crit = 'gini',\n",
    "            maxd = 6,\n",
    "            min_s = 10,\n",
    "            min_l = 5,\n",
    "            max_f = None)\n",
    "#Same as for decision tree except that we have here one more hyperparameter, \n",
    "# here put to 100 and that represents the number of bootstraps \n",
    "# (number of trees trained and then participating to the vote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how in the case of random forest the iso-probability lines are less binary than in the case of the decision tree? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_RF(X_3, y_3,\n",
    "            n_tree = 10, crit = 'gini',maxd = 6, min_s = 10, min_l = 5,\n",
    "            max_f = 'sqrt')\n",
    "# The difference here is that we set the max number of feature to split node to sqrt \n",
    "# (square root of the total number of features). \n",
    "#Before with None we were considering all the feature for node splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_RF(X_3, y_3,\n",
    "            n_tree = 10, crit = 'gini',maxd = 2, min_s = 10, min_l = 5, max_f = 'sqrt')\n",
    "# We change max depth from 6 to 2, \n",
    "# that would be equivalent to add some regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added a little bit of regularization in the single tree and so we can start to see less sharp borders. For the random forest it changes a bit the contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_RF(X_3, y_3,\n",
    "            n_tree = 1000, crit = 'gini',\n",
    "            maxd = 3, \n",
    "            min_s = 10,\n",
    "            min_l = 5,\n",
    "            max_f = 'sqrt')\n",
    "# with more trees we see more nuanced boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BAck to the ToC](#toc)\n",
    "\n",
    "## Random forest on the Cancer data set <a id=\"RFcancer\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "grid_values = {'n_estimators' : [50,100,200], \n",
    "               'max_depth':np.arange(4,10), ## I reduce the search space in the interest of time too\n",
    "               'min_samples_split':np.arange(2,12,2)}\n",
    "\n",
    "grid_tree = GridSearchCV(RandomForestClassifier(class_weight='balanced'), \n",
    "                                param_grid = grid_values, \n",
    "                                scoring='roc_auc',\n",
    "                                cv = 5,\n",
    "                                n_jobs=-1)\n",
    "grid_tree.fit(X_cancer_train, y_cancer_train)\n",
    "\n",
    "print(f'Grid best score (roc_auc): {grid_tree.best_score_:.3f}')\n",
    "print('Grid best parameter :')\n",
    "\n",
    "for k,v in grid_tree.best_params_.items():\n",
    "    print('{:>25}\\t{}'.format(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = grid_tree.best_estimator_\n",
    "\n",
    "w=RF.feature_importances_#get the weights\n",
    "\n",
    "featureW = pd.DataFrame( {'feature': df_cancer.columns[:-1] ,'weight':w} )\n",
    "\n",
    "# sort them by absolute value\n",
    "featureWsorted = featureW.sort_values(by=['weight'] , \n",
    "                                      ascending=False , \n",
    "                                      key=lambda col : col.abs())\n",
    "\n",
    "# get the non-null ones\n",
    "print('Features sorted per importance:')\n",
    "featureWsorted.loc[ featureWsorted[\"weight\"] !=0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the ToC](#toc)\n",
    "\n",
    "# Exercice : <a class=\"anchor\" id=\"exo\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Acharjee et al.2016](https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-016-1043-4) propose several -omic dataset which they used to predict and gain knowledge on various phenotypic traits in potatos.\n",
    "\n",
    "Here, we will concentrate on the their transcriptomics dataset and the phenotypic trait of the potato coloration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data comes in an excel spreadsheet with multiple sheet.\n",
    "\n",
    "Let's start with the metadata which contains our target variable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/12859_2016_1043_MOESM1_ESM.xlsx' )\n",
    "df.index = df.Genotype\n",
    "df.head()\n",
    "\n",
    "## color is encoded between 0 and 50. \n",
    "# A threshold of 20 is good here to categorize between more white and more yellow potatoes\n",
    "y = df[\"Flesh Colour\"]>=20\n",
    "y=y.replace({False:'White',True:'Yellow'})\n",
    "y.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read the sheet containing the transcriptomic data. Thankfully it has already been normalized so we only have minor adjustments to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('../data/12859_2016_1043_MOESM1_ESM.xlsx')\n",
    "dfT = pd.read_excel(xls, 'Transcriptomics data ')\n",
    "\n",
    "# transpose and keep only samples for which we have a target value\n",
    "dfTT = dfT.T.loc[y.index , :]\n",
    "dfTT.columns = dfT.loc[: , 'FeatureNum'].astype(str) \n",
    "dfTT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the gene column names are not very informative. According to the author, you can go to the supp. Mat. of another paper to get a (partial) annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal is to try to **predict potato color from the transcriptomic data** and, more importantly, to **retrieve which genes are the most important in this prediction**. Focus on the tree-based methods.\n",
    "\n",
    "Here, the goal is not so much to get a classifier, but to use the process to gain knowledge on the molecular mechanisms which underly potato color. \n",
    "\n",
    "#### IMPORTANT CONSIDERATIONS\n",
    "\n",
    "This dataset is, like many -omic dataset, fairly large (~15k genes have been quantified).\n",
    "If you do not want to wait forever for your grid search to finish, we recommend you follow these suggestions :\n",
    "\n",
    " * start your pipeline with some feature selection, such as `SelectKBest` (in our test, 20 features was enough to get a good predictor)\n",
    " * max depth can be fixed at 2, min samples split at 2 and min samples leaf at 1\n",
    " * The total number of parameter combinations will control the time it takes:\n",
    "     * 20 parameter combinations for random forest -> ~20s.\n",
    "     * 25 parameter combinations for boosted gradient -> ~10s.\n",
    "     * 25 parameter combinations for ADA boost -> ~20s.\n",
    "\n",
    "For example, for a random forest:\n",
    "```python\n",
    "grid_values = {'classifier__criterion': ['entropy','gini'],\n",
    "               'classifier__n_estimators':np.arange(1,1000,100), \n",
    "               'classifier__max_depth':[2,5],\n",
    "               'classifier__min_samples_split':[2],\n",
    "              'classifier__min_samples_leaf':[1]}\n",
    "```\n",
    "Represent : $2*10*2*1*1 = 40$ parameter combinations.\n",
    "\n",
    "> with all these recommendations, the grid search computation on my personnal computer took about a minute\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correction : splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r -13 solutions/solution_03_potato.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correction : pipeline and parameter space definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 14-40 solutions/solution_03_potato.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correction : gridsearch on the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 41-51 solutions/solution_03_potato.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correction : reporting the best model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 52-77 solutions/solution_03_potato.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correction : getting the features with the most importance; ie. which genes are the best predictors for potato color ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -r 78- solutions/solution_03_potato.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to ToC](#toc)\n",
    "\n",
    "# Appendices <a class=\"anchor\" id=\"APPENDIX\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to ToC](#toc)\n",
    "\n",
    "# ADA Boost <a class=\"anchor\" id=\"Ada-Boost\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Random Forest, you have a forest of trees, or rather, of *stumps*. However:\n",
    "\n",
    "* ADA boost considers **only the simplest type of trees : a single node with a yes or no question on one feature.** \n",
    "* Also, **in ADA boost stumps have different contributions in the final decision.** \n",
    "* Stumps are linked and there is an **order and a logical reason that links two contiguous stumps.**\n",
    "\n",
    "\n",
    "\n",
    "Each stump is made by **taking the previous stumps mistakes into account** and try to remedy them.\n",
    "How? By applying an importance weight on each sample : **missclassified points are given a higher weight** so that the next stumps are encouraged to focus on them.\n",
    "\n",
    "\n",
    "**Stumps have more to say in the classification if they have been better at classifying in general!** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ADA](../images/ADA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The voting weight for the stump $h_{t}$ is of the form $\\alpha_{t}=L*log(\\frac{1 - total.weigthed.error_{t}}{total.weigthed.error_{t}})$, where $L$ is the **learning rate**.\n",
    "\n",
    "> NB : If a specific stump misclassifies 100% of the data it is actually a really good classifier if you decide to just reverse the labels...\n",
    "\n",
    "\n",
    "The **learning rate** represents how much does the new iteration can deviate from the previous one. This is our new hyperparameter.\n",
    "\n",
    "\n",
    "The update of the importance of individual points is following the the same formula as voting and then put in an exponential to get the updated weights:\n",
    "\n",
    "$w^{t+1}_{i}=w^{t}_{i}e^{\\alpha_{t+1}}$ if $h_{t+1}$ made a mistake for point $i$\n",
    "\n",
    "> Those weights are then normalized.\n",
    "\n",
    "And at the end classification is made following a weighted average of the stumps:\n",
    "\n",
    "$G(x)=\\sum^{T}_{t=1}\\alpha_{t}G_{t}(x)$\n",
    "\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "Since we are only using stumps we get rid of all the other hyperparameters describing the tree topology (max depth, min samples split, min leaf split ).\n",
    "\n",
    "The only one left are the number of stumps (`n_estimators`) and the learning rate (`learning_rate`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import contour_ADA\n",
    "contour_ADA(X_3, y_3,\n",
    "             n_estimators = 20 ,\n",
    "             learning_rate = 0.1) #20 stumps, learning rate is 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_ADA(X_3, y_3, n_estimators = 20 , learning_rate= 1) #learning rate is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "l_rate=np.logspace(-2,1,30) \n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "n_estimator=[5,10,20,50]\n",
    "for i,ne in enumerate( n_estimator ):\n",
    "    scores_valid = []\n",
    "\n",
    "    for k in l_rate:\n",
    "        tree = AdaBoostClassifier(n_estimators=ne,learning_rate=k , algorithm=\"SAMME\")\n",
    "        tree.fit(X_3,y_3)\n",
    "        \n",
    "        y_valid_pred = tree.predict(X_3_valid)\n",
    "\n",
    "        scores_valid.append(accuracy_score(y_3_valid,y_valid_pred))\n",
    "        \n",
    "    ax.plot(l_rate, scores_valid,linewidth=3,label='N_estimators= '+str(ne))\n",
    "\n",
    "ax.set_xlabel('Learning rate')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_xscale('log')\n",
    "ax.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two hyperparameters number of of stumps and learning rate are actually interdependent. \n",
    "\n",
    "The law associating the two is not obvious but just keep in mind that **if the number of stumps is large you don't need a big learning rate.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_values = {'n_estimators':np.arange(500,1500,250), \n",
    "               'learning_rate':np.logspace(-3,1,5) \n",
    "               }\n",
    "\n",
    "grid_ADA_roc_auc = GridSearchCV(AdaBoostClassifier(algorithm=\"SAMME\"), \n",
    "                             param_grid = grid_values, \n",
    "                             scoring='roc_auc',\n",
    "                             n_jobs=-1)\n",
    "\n",
    "grid_ADA_roc_auc.fit(X_cancer_train, y_cancer_train)\n",
    "\n",
    "y_decision_fn_scores_roc_auc=grid_ADA_roc_auc.score(X_cancer_test,y_cancer_test)\n",
    "\n",
    "print('Grid best parameter (max. roc_auc): ', grid_ADA_roc_auc.best_params_)\n",
    "print('Grid best score (roc_auc): ', grid_ADA_roc_auc.best_score_)\n",
    "print('Grid best parameter (max. roc_auc) model on test: ', y_decision_fn_scores_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred_test_c=grid_ADA_roc_auc.predict(X_cancer_test)\n",
    "\n",
    "    \n",
    "bestNE = grid_ADA_roc_auc.best_params_[\"n_estimators\"]\n",
    "bestLR = grid_ADA_roc_auc.best_params_[\"learning_rate\"]\n",
    "\n",
    "plotTitle = \"\"\"ADA boost - number of estimators: {}\n",
    "learning rate: {}\n",
    "Accuracy: {:.3f}\"\"\".format(bestNE,bestLR,\n",
    "                           accuracy_score(y_cancer_test,y_pred_test_c) )\n",
    "\n",
    "confusion_m_cancer = confusion_matrix(y_cancer_test, y_pred_test_c)\n",
    "\n",
    "plt.figure(figsize=(5.5,4))\n",
    "sns.heatmap(confusion_m_cancer, annot=True , \n",
    "            xticklabels=['benign','malignant'], \n",
    "            yticklabels=['benign','malignant'])\n",
    "plt.title('test {} : {:.3f}'.format( \"accuracy\" , \n",
    "                                    accuracy_score(y_cancer_test,y_pred_test_c)  ))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_estimator(grid_ADA_roc_auc,X_cancer_test, y_cancer_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to ToC](#toc)\n",
    "\n",
    "# Boosted gradient <a class=\"anchor\" id=\"Boosted-Gradient\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can already imagine from the name, in boosted gradient the \n",
    "optimization algorithm follows the gradient of a loss function (or a likelihood function!).\n",
    "\n",
    "Just like ADAboost and random forest, boosted gradient **creates many trees and datasets**. \n",
    "\n",
    "In oposition to ADAboost each tree (not limited to stumps this time) is **fitted on the error from the previous tree** rather than a re-weighted dataset.\n",
    "\n",
    "In the end you have a quorum of trees for which the **voting is done proportionally to the gradient value.**\n",
    "\n",
    "![boosted](../images/boosted.png)\n",
    "\n",
    "\n",
    "Boosted **gradient** refers to the gradient of a **loss function**.\n",
    "\n",
    "When performing classification, the algorithm transforms the leaves scores into **log-odds ratio**, thus internally **switching from a classification problem to a regression one**.\n",
    "\n",
    "This new perspective enables highly non linear classification rules, based on logistic regression.\n",
    "\n",
    "\n",
    "Then, from tree to tree (ie. iterations), the algorithm tries to minimize the difference between the predicted log odds and its labeled values (1 or 0).\n",
    "\n",
    "> This method is naturally adapted to regression as well, given that when we do a classification we actually have to transform into a regression problem.\n",
    "\n",
    "#### hyperparameters\n",
    "\n",
    "* single tree hyperparameters : \n",
    "    - Max Tree depth : `max_depth`\n",
    "    - Min Splitting of nodes : `min_samples_split`\n",
    "    - Min Splitting of leaves : `min_samples_leaf`\n",
    "    - Max number of features : `max_features`\n",
    "* number of iterations : `n_estimators`\n",
    "* learning rate `learning_rate`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import contour_BG\n",
    "contour_BG(X_3,y_3,\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=4,min_samples_split=20,min_samples_leaf=10,max_features='sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## more iterations\n",
    "contour_BG(X_3,y_3,\n",
    "            n_estimators=1000,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=4,min_samples_split=20,min_samples_leaf=10,max_features='sqrt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosted gradient on the penguin dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_values = {'learning_rate':np.logspace(-1,1,5),\n",
    "                'n_estimators':np.arange(100,501,100), \n",
    "               'max_depth':[2,3],\n",
    "               'min_samples_split':[20],\n",
    "              'min_samples_leaf':[10]}\n",
    "\n",
    "grid_boosted_roc_auc = GridSearchCV(GradientBoostingClassifier(), \n",
    "                             param_grid = grid_values, \n",
    "                             scoring='roc_auc_ovr_weighted',n_jobs=-1)\n",
    "\n",
    "grid_boosted_roc_auc.fit(X_penguin_train, y_penguin_train)\n",
    "\n",
    "y_decision_fn_scores_roc_auc=grid_boosted_roc_auc.score(X_penguin_test, y_penguin_test)\n",
    "\n",
    "print('Grid best parameter (max. roc_auc_ovr_weighted): ', grid_boosted_roc_auc.best_params_)\n",
    "print('Grid best score (roc_auc_ovr_weighted): ', grid_boosted_roc_auc.best_score_)\n",
    "print('Grid best parameter (max. roc_auc_ovr_weighted) model on test: ', y_decision_fn_scores_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predicting the labels on the test set    \n",
    "y_pred_test=grid_boosted_roc_auc.predict(X_penguin_test)\n",
    "\n",
    "confusion_m = confusion_matrix(y_penguin_test, y_pred_test)\n",
    "\n",
    "plt.figure(figsize=(5.5,4))\n",
    "sns.heatmap(confusion_m, annot=True , \n",
    "            xticklabels=['Adelie','Chinstrap','Gentoo'], \n",
    "            yticklabels=['Adelie','Chinstrap','Gentoo'])\n",
    "plt.title('test {} : {:.3f}'.format( \"accuracy\" , \n",
    "                                    accuracy_score(y_penguin_test,y_pred_test)  ))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BG = GradientBoostingClassifier(learning_rate=grid_boosted_roc_auc.best_params_['learning_rate'],\n",
    "                              n_estimators=grid_boosted_roc_auc.best_params_['n_estimators'],\n",
    "                             max_depth=grid_boosted_roc_auc.best_params_['max_depth'],\n",
    "                             min_samples_leaf=grid_boosted_roc_auc.best_params_['min_samples_leaf'],\n",
    "                             min_samples_split=grid_boosted_roc_auc.best_params_['min_samples_split'])\n",
    "BG.fit(X_penguin_train, y_penguin_train)\n",
    "w=BG.feature_importances_#get the weights\n",
    "\n",
    "\n",
    "featureW = pd.DataFrame( {'feature': X_penguin.columns,'weight':w} )\n",
    "\n",
    "# sort them by absolute value\n",
    "featureWsorted = featureW.sort_values(by=['weight'] , \n",
    "                                      ascending=False , \n",
    "                                      key=lambda col : col.abs())\n",
    "\n",
    "# get the non-null ones\n",
    "print('Features sorted per importance:')\n",
    "featureWsorted.loc[ featureWsorted[\"weight\"] !=0 ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_introml2024)",
   "language": "python",
   "name": "conda_introml2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
